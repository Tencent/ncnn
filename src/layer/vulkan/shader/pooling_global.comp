// Tencent is pleased to support the open source community by making ncnn available.
//
// Copyright (C) 2019 THL A29 Limited, a Tencent company. All rights reserved.
//
// Licensed under the BSD 3-Clause License (the "License"); you may not use this file except
// in compliance with the License. You may obtain a copy of the License at
//
// https://opensource.org/licenses/BSD-3-Clause
//
// Unless required by applicable law or agreed to in writing, software distributed
// under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR
// CONDITIONS OF ANY KIND, either express or implied. See the License for the
// specific language governing permissions and limitations under the License.

#version 450

#if NCNN_fp16_storage
#extension GL_EXT_shader_16bit_storage: require
#endif
#if NCNN_fp16_arithmetic
#extension GL_EXT_shader_explicit_arithmetic_types_float16: require
#endif

#define FLT_MAX 3.402823466e+38

layout (constant_id = 0) const int pooling_type = 0;

#define shape_constant_id_offset 1
layout (constant_id = shape_constant_id_offset + 0) const int dims = 0;
layout (constant_id = shape_constant_id_offset + 1) const int w = 0;
layout (constant_id = shape_constant_id_offset + 2) const int h = 0;
layout (constant_id = shape_constant_id_offset + 3) const int c = 0;
layout (constant_id = shape_constant_id_offset + 4) const int cstep = 0;

layout (constant_id = shape_constant_id_offset + 5) const int outdims = 0;
layout (constant_id = shape_constant_id_offset + 6) const int outw = 0;
layout (constant_id = shape_constant_id_offset + 7) const int outh = 0;
layout (constant_id = shape_constant_id_offset + 8) const int outc = 0;
layout (constant_id = shape_constant_id_offset + 9) const int outcstep = 0;

#if NCNN_image_shader
layout (binding = 0) uniform unfp sampler3D bottom_blob;
layout (binding = 1, imfmtc1) writeonly uniform unfp image3D top_blob;
#else
layout (binding = 0) readonly buffer bottom_blob { sfp bottom_blob_data[]; };
layout (binding = 1) writeonly buffer top_blob { sfp top_blob_data[]; };
#endif

layout (push_constant) uniform parameter
{
    int dims;
    int w;
    int h;
    int c;
    int cstep;

    int outdims;
    int outw;
    int outh;
    int outc;
    int outcstep;

    uint perThreadWorkLoad1d;
    uint perThreadWorkLoad2dInX;
    uint perThreadWorkLoad2dInY;
} p;

#define GROUP_SIZE 256
shared float sharedData0[GROUP_SIZE];
shared float sharedData1[GROUP_SIZE];

shared uint shared0Size;
shared uint shared1Size;

void main()
{
    uvec3 DTid = gl_GlobalInvocationID;
    uvec3 GTid = gl_LocalInvocationID;
    uvec3 Gid  = gl_WorkGroupID;
    uint  GTIndex = gl_LocalInvocationIndex; //flatted index in a work group

    if(GTIndex == 0)
    {
        shared0Size = 0;
        shared1Size = 0;
    }
    barrier();

#if NCNN_image_shader
    // use for 2-dimension image
    uint threadWorkLoadX = p.perThreadWorkLoad2dInX;
    uint threadWorkLoadY = p.perThreadWorkLoad2dInY;
#else
    // use for 1-dimension buffer
    uint threadWorkLoad = p.perThreadWorkLoad1d;
    uint groupWorkLoadEnd = (1 + Gid.z) * psc(cstep);
    uint workLoadOffset = Gid.z * psc(cstep) + threadWorkLoad * GTIndex;
#endif

    afp res;

    if (pooling_type == 0)
    {
        res = afp(-FLT_MAX);

#if NCNN_image_shader
        // reduction to sharedData0
        {
            float temp = (-FLT_MAX);

            uint threadWorkLoadBeginX = GTid.x * threadWorkLoadX;
            uint threadWorkLoadBeginY = GTid.y * threadWorkLoadY;
            uint threadWorkLoadEndX = threadWorkLoadBeginX + threadWorkLoadX;
            uint threadWorkLoadEndY = threadWorkLoadBeginY + threadWorkLoadY;
            uint threadWorkLoadEndXValid = min(threadWorkLoadEndX, psc(w));
            uint threadWorkLoadEndYValid = min(threadWorkLoadEndY, psc(h));

            uint validSize = 0;
            for(uint y = threadWorkLoadBeginY; y < threadWorkLoadEndYValid; ++y)
                for(uint x = threadWorkLoadBeginX; x < threadWorkLoadEndXValid; ++x)
                {
                    afp v = afp(image3d_ld1(bottom_blob, ivec3(x, y, Gid.z)));
                    temp = max(temp, v);

                    validSize++;
                }
            
            if(validSize > 0)
            {
                atomicAdd(shared0Size, 1);
            }

            sharedData0[GTIndex] = temp;
        }
#else
        // reduction to sharedData0
        {
            float temp = (-FLT_MAX);
            uint threadWorkLoadBegin = workLoadOffset;
            uint threadWorkLoadEnd   = threadWorkLoadBegin + threadWorkLoad;
            uint threadWorkLoadEndValid = min(threadWorkLoadEnd, groupWorkLoadEnd);

            for(uint i = threadWorkLoadBegin; i < threadWorkLoadEndValid; ++i)
            {
                float var = float(buffer_ld1(bottom_blob_data, i));
                temp = max(temp, var);
            }

            if(threadWorkLoadEndValid > threadWorkLoadBegin)
            {
                atomicAdd(shared0Size, 1);
            }

            sharedData0[GTIndex] = temp;
        }
#endif
        barrier();

        // reduction to sharedData1
        const uint SHARED_REDUCTION_WORKLOAD = 16;
        const uint SHARED_REDUCTION_SIZE = (GROUP_SIZE / SHARED_REDUCTION_WORKLOAD);
        if(GTIndex < SHARED_REDUCTION_SIZE)
        {
            float temp = (-FLT_MAX);
            uint reductionBegin = GTIndex * SHARED_REDUCTION_WORKLOAD;
            uint reductionEnd = reductionBegin + SHARED_REDUCTION_WORKLOAD;
            uint reductionEndValid = min(shared0Size, reductionEnd);

            for(uint i = reductionBegin; i < reductionEndValid; ++i)
            {
                temp = max(temp, sharedData0[i]);
            }

            if(reductionEndValid > reductionBegin)
            {
                atomicAdd(shared1Size, 1);
            }

            sharedData1[GTIndex] = temp;
        }

        barrier();

        // reduction to final output
        if(GTIndex == 0)
        {
            afp temp = afp(-FLT_MAX);

            for(uint i = 0; i < shared1Size; ++i)
            {
                temp = max(temp, afp(sharedData1[i]));
            }
            res = max(res, temp);
#if NCNN_image_shader
            image3d_st1(top_blob, ivec3(Gid.z, 0, 0), res);
#else
            buffer_st1(top_blob_data, Gid.z, res);
#endif
        }
    }

    if(pooling_type == 1)
    {
#if NCNN_image_shader
        // reduction to sharedData0
        {
            float temp = 0.f;

            uint threadWorkLoadBeginX = GTid.x * threadWorkLoadX;
            uint threadWorkLoadBeginY = GTid.y * threadWorkLoadY;
            uint threadWorkLoadEndX = threadWorkLoadBeginX + threadWorkLoadX;
            uint threadWorkLoadEndY = threadWorkLoadBeginY + threadWorkLoadY;
            uint threadWorkLoadEndXValid = min(threadWorkLoadEndX, psc(w));
            uint threadWorkLoadEndYValid = min(threadWorkLoadEndY, psc(h));

            uint validSize = 0;
            for(uint y = threadWorkLoadBeginY; y < threadWorkLoadEndYValid; ++y)
                for(uint x = threadWorkLoadBeginX; x < threadWorkLoadEndXValid; ++x)
                {
                    temp += float(image3d_ld1(bottom_blob, ivec3(x, y, Gid.z)));
                    validSize++;
                }
            
            if(validSize > 0)
            {
                temp = (temp / validSize);
                atomicAdd(shared0Size, 1);
            }

            sharedData0[GTIndex] = temp;
        }
#else
        // reduction to sharedData0
        {
            float temp = 0.f;

            uint threadWorkLoadBegin = workLoadOffset;
            uint threadWorkLoadEnd   = threadWorkLoadBegin + threadWorkLoad;
            uint threadWorkLoadEndValid = min(threadWorkLoadEnd, groupWorkLoadEnd);

            uint validSize = threadWorkLoadEndValid - threadWorkLoadBegin;

            for(uint i = threadWorkLoadBegin; i < threadWorkLoadEndValid; ++i)
            {
                temp += float(buffer_ld1(bottom_blob_data, i));
            }
            
            if(threadWorkLoadEndValid > threadWorkLoadBegin)
            {
                temp = (temp / validSize);
                atomicAdd(shared0Size, 1);
            }

            sharedData0[GTIndex] = temp;
        }
#endif
        barrier();

        // reduction to sharedData1
        const uint SHARED_REDUCTION_WORKLOAD = 16;
        const uint SHARED_REDUCTION_SIZE = (GROUP_SIZE / SHARED_REDUCTION_WORKLOAD);
        if(GTIndex < SHARED_REDUCTION_SIZE)
        {
            float temp = 0.f;

            uint reductionBegin = GTIndex * SHARED_REDUCTION_WORKLOAD;
            uint reductionEnd = reductionBegin + SHARED_REDUCTION_WORKLOAD;

            uint reductionEndValid = min(shared0Size, reductionEnd);
            uint validSize = reductionEndValid - reductionBegin;

            for(uint i = reductionBegin; i < reductionEndValid; ++i)
            {
                temp += sharedData0[i];
            }

            if(reductionEndValid > reductionBegin)
            {
                temp = (temp / validSize);
                atomicAdd(shared1Size, 1);
            }

            sharedData1[GTIndex] = temp;
        }
        
        barrier();

        // reduction to final output
        if(GTIndex == 0)
        {
            float temp = 0.f;

            for(uint i = 0; i < shared1Size; ++i)
            {
                temp += sharedData1[i];
            }

            res = afp(temp / shared1Size);

#if NCNN_image_shader
            image3d_st1(top_blob, ivec3(Gid.z, 0, 0), res);
#else
            buffer_st1(top_blob_data, Gid.z, res);
#endif
        }
    }
}
