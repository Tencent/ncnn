// Tencent is pleased to support the open source community by making ncnn available.
//
// Copyright (C) 2020 THL A29 Limited, a Tencent company. All rights reserved.
//
// Licensed under the BSD 3-Clause License (the "License"); you may not use this file except
// in compliance with the License. You may obtain a copy of the License at
//
// https://opensource.org/licenses/BSD-3-Clause
//
// Unless required by applicable law or agreed to in writing, software distributed
// under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR
// CONDITIONS OF ANY KIND, either express or implied. See the License for the
// specific language governing permissions and limitations under the License.

#version 450

#if NCNN_fp16_storage
#extension GL_EXT_shader_16bit_storage: require
struct sfpvec8 { f16vec4 abcd; f16vec4 efgh; };
#endif
#if NCNN_fp16_arithmetic
#extension GL_EXT_shader_explicit_arithmetic_types_float16: require
#endif

#define FLT_MAX 3.402823466e+38

layout (constant_id = 0) const int pooling_type = 0;

#define shape_constant_id_offset 1
layout (constant_id = shape_constant_id_offset + 0) const int dims = 0;
layout (constant_id = shape_constant_id_offset + 1) const int w = 0;
layout (constant_id = shape_constant_id_offset + 2) const int h = 0;
layout (constant_id = shape_constant_id_offset + 3) const int c = 0;
layout (constant_id = shape_constant_id_offset + 4) const int cstep = 0;

layout (constant_id = shape_constant_id_offset + 5) const int outdims = 0;
layout (constant_id = shape_constant_id_offset + 6) const int outw = 0;
layout (constant_id = shape_constant_id_offset + 7) const int outh = 0;
layout (constant_id = shape_constant_id_offset + 8) const int outc = 0;
layout (constant_id = shape_constant_id_offset + 9) const int outcstep = 0;

#if NCNN_image_shader
layout (binding = 0) uniform unfp sampler3D bottom_blob;
layout (binding = 1, imfmtc4) writeonly uniform unfp image3D top_blob;
#else
layout (binding = 0) readonly buffer bottom_blob { sfpvec8 bottom_blob_data[]; };
layout (binding = 1) writeonly buffer top_blob { sfpvec8 top_blob_data[]; };
#endif

layout (push_constant) uniform parameter
{
    int dims;
    int w;
    int h;
    int c;
    int cstep;

    int outdims;
    int outw;
    int outh;
    int outc;
    int outcstep;

    uint perThreadWorkLoad1d;
    uint perThreadWorkLoad2dInX;
    uint perThreadWorkLoad2dInY;
} p;

#define GROUP_SIZE 256
shared mat2x4 sharedData0[GROUP_SIZE];
shared mat2x4 sharedData1[GROUP_SIZE];

shared uint shared0Size;
shared uint shared1Size;

void main()
{
     uvec3 DTid = gl_GlobalInvocationID;
    uvec3 GTid = gl_LocalInvocationID;
    uvec3 Gid  = gl_WorkGroupID;
    uint  GTIndex = gl_LocalInvocationIndex; //flatted index in a work group

    if(GTIndex == 0)
    {
        shared0Size = 0;
        shared1Size = 0;
    }
    barrier();

#if NCNN_image_shader
    // use for 2-dimension image
    uint threadWorkLoadX = p.perThreadWorkLoad2dInX;
    uint threadWorkLoadY = p.perThreadWorkLoad2dInY;
#else
    // use for 1-dimension buffer
    uint threadWorkLoad = p.perThreadWorkLoad1d;
    uint groupWorkLoadEnd = (1 + Gid.z) * psc(cstep);
    uint workLoadOffset = Gid.z * psc(cstep) + threadWorkLoad * GTIndex;
#endif

    afpvec8 res;

    if (pooling_type == 0)
    {
        res = afpvec8(afpvec4(-FLT_MAX), afpvec4(-FLT_MAX));

#if NCNN_image_shader
        // reduction to sharedData0
        {
            mat2x4 temp = mat2x4(vec4(-FLT_MAX), vec4(-FLT_MAX));

            uint threadWorkLoadBeginX = GTid.x * threadWorkLoadX;
            uint threadWorkLoadBeginY = GTid.y * threadWorkLoadY;
            uint threadWorkLoadEndX = threadWorkLoadBeginX + threadWorkLoadX;
            uint threadWorkLoadEndY = threadWorkLoadBeginY + threadWorkLoadY;
            uint threadWorkLoadEndXValid = min(threadWorkLoadEndX, psc(w));
            uint threadWorkLoadEndYValid = min(threadWorkLoadEndY, psc(h));

            uint validSize = 0;
            for(uint y = threadWorkLoadBeginY; y < threadWorkLoadEndYValid; ++y)
                for(uint x = threadWorkLoadBeginX; x < threadWorkLoadEndXValid; ++x)
                {
                    afpvec8 v = image3d_ld8(bottom_blob, ivec3(x, y, Gid.z));
                    temp[0] = max(temp[0], v[0]);
                    temp[1] = max(temp[1], v[1]);

                    validSize++;
                }
            
            if(validSize > 0)
            {
                atomicAdd(shared0Size, 1);
            }
            sharedData0[GTIndex] = temp;
        }
#else
        // reduction to sharedData0
        {
            mat2x4 temp = mat2x4(vec4(-FLT_MAX), vec4(-FLT_MAX));
            uint threadWorkLoadBegin = workLoadOffset;
            uint threadWorkLoadEnd   = threadWorkLoadBegin + threadWorkLoad;
            uint threadWorkLoadEndValid = min(threadWorkLoadEnd, groupWorkLoadEnd);

            for(uint i = threadWorkLoadBegin; i < threadWorkLoadEndValid; ++i)
            {
                mat2x4 var = buffer_ld8(bottom_blob_data, i);
                temp[0] = max(temp[0], var[0]);
                temp[1] = max(temp[1], var[1]);
            }

            if(threadWorkLoadEndValid > threadWorkLoadBegin)
            {
                atomicAdd(shared0Size, 1);
            }
            sharedData0[GTIndex] = temp;
        }
#endif
        barrier();

        // reduction to sharedData1
        const uint SHARED_REDUCTION_WORKLOAD = 16;
        const uint SHARED_REDUCTION_SIZE = (GROUP_SIZE / SHARED_REDUCTION_WORKLOAD);
        if(GTIndex < SHARED_REDUCTION_SIZE)
        {
            mat2x4 temp = mat2x4(vec4(-FLT_MAX), vec4(-FLT_MAX));
            uint reductionBegin = GTIndex * SHARED_REDUCTION_WORKLOAD;
            uint reductionEnd = reductionBegin + SHARED_REDUCTION_WORKLOAD;
            uint reductionEndValid = min(shared0Size, reductionEnd);

            for(uint i = reductionBegin; i < reductionEndValid; ++i)
            {
                temp[0] = max(temp[0], sharedData0[i][0]);
                temp[1] = max(temp[1], sharedData0[i][1]);
            }

            if(reductionEndValid > reductionBegin)
            {
                atomicAdd(shared1Size, 1);
            }
            sharedData1[GTIndex] = temp;
        }
        
        barrier();

        // reduction to final output
        if(GTIndex == 0)
        {
            mat2x4 temp = mat2x4(vec4(-FLT_MAX), vec4(-FLT_MAX));

            for(uint i = 0; i < shared1Size; ++i)
            {
                temp[0] = max(temp[0], sharedData1[i][0]);
                temp[1] = max(temp[1], sharedData1[i][1]);
            }
            res[0] = max(res[0], afpvec4(temp[0]));
            res[1] = max(res[1], afpvec4(temp[1]));

#if NCNN_image_shader
            image3d_st8(top_blob, ivec3(Gid.z, 0, 0), res);
#else
            buffer_st8(top_blob_data, Gid.z, res);            
#endif
        }
    }

    if(pooling_type == 1)
    {
#if NCNN_image_shader
        // reduction to sharedData0
        {
            mat2x4 temp = mat2x4(vec4(0.f), vec4(0.f));

            uint threadWorkLoadBeginX = GTid.x * threadWorkLoadX;
            uint threadWorkLoadBeginY = GTid.y * threadWorkLoadY;
            uint threadWorkLoadEndX = threadWorkLoadBeginX + threadWorkLoadX;
            uint threadWorkLoadEndY = threadWorkLoadBeginY + threadWorkLoadY;
            uint threadWorkLoadEndXValid = min(threadWorkLoadEndX, psc(w));
            uint threadWorkLoadEndYValid = min(threadWorkLoadEndY, psc(h));

            uint validSize = 0;
            for(uint y = threadWorkLoadBeginY; y < threadWorkLoadEndYValid; ++y)
                for(uint x = threadWorkLoadBeginX; x < threadWorkLoadEndXValid; ++x)
                {
                    mat2x4 v =  image3d_ld8(bottom_blob, ivec3(x, y, Gid.z));
                    temp[0] += v[0];
                    temp[1] += v[1];

                    validSize++;
                }
            
            if(validSize > 0)
            {
                temp[1] = (temp[0] / validSize);
                temp[1] = (temp[1] / validSize);
                atomicAdd(shared0Size, 1);
            }

            sharedData0[GTIndex] = temp;
        }
#else
        // reduction to sharedData0
        {
            mat2x4 temp = mat2x4(vec4(0.f), vec4(0.f));

            uint threadWorkLoadBegin = workLoadOffset;
            uint threadWorkLoadEnd   = threadWorkLoadBegin + threadWorkLoad;
            uint threadWorkLoadEndValid = min(threadWorkLoadEnd, groupWorkLoadEnd);

            uint validSize = threadWorkLoadEndValid - threadWorkLoadBegin;

            for(uint i = threadWorkLoadBegin; i < threadWorkLoadEndValid; ++i)
            {
                mat2x4 v =  buffer_ld8(bottom_blob_data, i);
                temp[0] += v[0];
                temp[1] += v[1];
            }
            
            if(threadWorkLoadEndValid > threadWorkLoadBegin)
            {
                temp[1] = (temp[0] / validSize);
                temp[1] = (temp[1] / validSize);

                atomicAdd(shared0Size, 1);
            }

            sharedData0[GTIndex] = temp;
        }
#endif
        barrier();

        // reduction to sharedData1
        const uint SHARED_REDUCTION_WORKLOAD = 16;
        const uint SHARED_REDUCTION_SIZE = (GROUP_SIZE / SHARED_REDUCTION_WORKLOAD);
        if(GTIndex < SHARED_REDUCTION_SIZE)
        {
            mat2x4 temp = mat2x4(vec4(0.f), vec4(0.f));

            uint reductionBegin = GTIndex * SHARED_REDUCTION_WORKLOAD;
            uint reductionEnd = reductionBegin + SHARED_REDUCTION_WORKLOAD;

            uint reductionEndValid = min(shared0Size, reductionEnd);
            uint validSize = reductionEndValid - reductionBegin;

            for(uint i = reductionBegin; i < reductionEndValid; ++i)
            {
                temp[0] += sharedData0[i][0];
                temp[1] += sharedData0[i][1];
            }

            if(reductionEndValid > reductionBegin)
            {
                temp[0] = (temp[0] / validSize);
                temp[1] = (temp[1] / validSize);

                atomicAdd(shared1Size, 1);
            }

            sharedData1[GTIndex] = temp;
        }
        
        barrier();

        // reduction to final output
        if(GTIndex == 0)
        {
            mat2x4 temp = mat2x4(vec4(0.f), vec4(0.f));

            for(uint i = 0; i < shared1Size; ++i)
            {
                temp[0] += sharedData1[i][0];
                temp[1] += sharedData1[i][1];
            }

            res[0] = afpvec4(temp[0] / shared1Size);
            res[1] = afpvec4(temp[1] / shared1Size);

#if NCNN_image_shader
            image3d_st8(top_blob, ivec3(Gid.z, 0, 0), res);
#else
            buffer_st8(top_blob_data, Gid.z, res);            
#endif
        }
    }
}
