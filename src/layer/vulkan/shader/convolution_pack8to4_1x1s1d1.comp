// Tencent is pleased to support the open source community by making ncnn available.
//
// Copyright (C) 2020 THL A29 Limited, a Tencent company. All rights reserved.
//
// Licensed under the BSD 3-Clause License (the "License"); you may not use this file except
// in compliance with the License. You may obtain a copy of the License at
//
// https://opensource.org/licenses/BSD-3-Clause
//
// Unless required by applicable law or agreed to in writing, software distributed
// under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR
// CONDITIONS OF ANY KIND, either express or implied. See the License for the
// specific language governing permissions and limitations under the License.

#version 450

#if NCNN_fp16_storage
#extension GL_EXT_shader_16bit_storage: require
struct sfpvec8 { f16vec4 abcd; f16vec4 efgh; };
#endif
#if NCNN_fp16_arithmetic
#extension GL_EXT_shader_explicit_arithmetic_types_float16: require
#endif

#extension GL_GOOGLE_include_directive: enable
#include "vulkan_activation.comp"

layout (constant_id = 0) const int bias_term = 0;
layout (constant_id = 1) const int activation_type = 0;
layout (constant_id = 2) const float activation_param_0 = 0;
layout (constant_id = 3) const float activation_param_1 = 0;

#define shape_constant_id_offset 4
layout (constant_id = shape_constant_id_offset + 0) const int w = 0;
layout (constant_id = shape_constant_id_offset + 1) const int h = 0;
layout (constant_id = shape_constant_id_offset + 2) const int c = 0;
layout (constant_id = shape_constant_id_offset + 3) const int cstep = 0;

layout (constant_id = shape_constant_id_offset + 4) const int outw = 0;
layout (constant_id = shape_constant_id_offset + 5) const int outh = 0;
layout (constant_id = shape_constant_id_offset + 6) const int outc = 0;
layout (constant_id = shape_constant_id_offset + 7) const int outcstep = 0;

#if NCNN_image_shader
layout (binding = 0) uniform unfp sampler3D bottom_blob;
layout (binding = 1, imfmtc4) writeonly uniform unfp image3D top_blob;
layout (binding = 2) uniform unfp sampler3D weight_blob;
layout (binding = 3) uniform unfp sampler3D bias_blob;
#else
layout (binding = 0) readonly buffer bottom_blob { sfpvec8 bottom_blob_data[]; };
layout (binding = 1) writeonly buffer top_blob { sfpvec4 top_blob_data[]; };
layout (binding = 2) readonly buffer weight_blob { sfpvec8 weight_data[]; };
layout (binding = 3) readonly buffer bias_blob { sfpvec4 bias_data[]; };
#endif

layout (push_constant) uniform parameter
{
    int w;
    int h;
    int c;
    int cstep;

    int outw;
    int outh;
    int outc;
    int outcstep;
} p;

void main()
{
    int gx = int(gl_GlobalInvocationID.x) * 4;
    int gy = int(gl_GlobalInvocationID.y);

#if NCNN_image_shader
    if (gx >= psc(outw) * psc(outh) || gy >= psc(outc))
        return;
#else
    if (gx >= psc(outcstep) || gy >= psc(outc))
        return;
#endif

    afpvec4 sum0;
    afpvec4 sum1;
    afpvec4 sum2;
    afpvec4 sum3;

    if (bias_term == 1)
    {
#if NCNN_image_shader
        afpvec4 b = image3d_ld4(bias_blob, ivec3(gy, 0, 0));
#else
        afpvec4 b = buffer_ld4(bias_data, gy);
#endif
        sum0 = b;
        sum1 = b;
        sum2 = b;
        sum3 = b;
    }
    else
    {
        sum0 = afpvec4(0.f);
        sum1 = afpvec4(0.f);
        sum2 = afpvec4(0.f);
        sum3 = afpvec4(0.f);
    }

#if NCNN_image_shader
    ivec4 gx4 = gx + ivec4(0, 1, 2, 3);

    ivec4 sy4 = gx4 / psc(w);
    ivec4 sx4 = gx4 % psc(w);

    for (int z = 0; z < psc(c); z++)
    {
        afpvec8 v0 = image3d_ld8(bottom_blob, ivec3(sx4.r, sy4.r, z));
        afpvec8 v1 = image3d_ld8(bottom_blob, ivec3(sx4.g, sy4.g, z));
        afpvec8 v2 = image3d_ld8(bottom_blob, ivec3(sx4.b, sy4.b, z));
        afpvec8 v3 = image3d_ld8(bottom_blob, ivec3(sx4.a, sy4.a, z));

        afpvec8 k0 = image3d_ld8(weight_blob, ivec3(0, z, gy));
        afpvec8 k1 = image3d_ld8(weight_blob, ivec3(1, z, gy));
        afpvec8 k2 = image3d_ld8(weight_blob, ivec3(2, z, gy));
        afpvec8 k3 = image3d_ld8(weight_blob, ivec3(3, z, gy));

        // sum += v * k;
        sum0.r += dot(v0[0], k0[0]) + dot(v0[1], k0[1]);
        sum0.g += dot(v0[0], k1[0]) + dot(v0[1], k1[1]);
        sum0.b += dot(v0[0], k2[0]) + dot(v0[1], k2[1]);
        sum0.a += dot(v0[0], k3[0]) + dot(v0[1], k3[1]);

        sum1.r += dot(v1[0], k0[0]) + dot(v1[1], k0[1]);
        sum1.g += dot(v1[0], k1[0]) + dot(v1[1], k1[1]);
        sum1.b += dot(v1[0], k2[0]) + dot(v1[1], k2[1]);
        sum1.a += dot(v1[0], k3[0]) + dot(v1[1], k3[1]);

        sum2.r += dot(v2[0], k0[0]) + dot(v2[1], k0[1]);
        sum2.g += dot(v2[0], k1[0]) + dot(v2[1], k1[1]);
        sum2.b += dot(v2[0], k2[0]) + dot(v2[1], k2[1]);
        sum2.a += dot(v2[0], k3[0]) + dot(v2[1], k3[1]);

        sum3.r += dot(v3[0], k0[0]) + dot(v3[1], k0[1]);
        sum3.g += dot(v3[0], k1[0]) + dot(v3[1], k1[1]);
        sum3.b += dot(v3[0], k2[0]) + dot(v3[1], k2[1]);
        sum3.a += dot(v3[0], k3[0]) + dot(v3[1], k3[1]);
    }
#else
    int w_offset = gy * psc(c) * 4;
    int v_offset = gx;

    for (int z = 0; z < psc(c); z++)
    {
        afpvec8 v0 = buffer_ld8(bottom_blob_data, v_offset + 0);
        afpvec8 v1 = buffer_ld8(bottom_blob_data, v_offset + 1);
        afpvec8 v2 = buffer_ld8(bottom_blob_data, v_offset + 2);
        afpvec8 v3 = buffer_ld8(bottom_blob_data, v_offset + 3);

        afpvec8 k0 = buffer_ld8(weight_data, w_offset + 0);
        afpvec8 k1 = buffer_ld8(weight_data, w_offset + 1);
        afpvec8 k2 = buffer_ld8(weight_data, w_offset + 2);
        afpvec8 k3 = buffer_ld8(weight_data, w_offset + 3);

        // sum += v * k;
        sum0.r += dot(v0[0], k0[0]) + dot(v0[1], k0[1]);
        sum0.g += dot(v0[0], k1[0]) + dot(v0[1], k1[1]);
        sum0.b += dot(v0[0], k2[0]) + dot(v0[1], k2[1]);
        sum0.a += dot(v0[0], k3[0]) + dot(v0[1], k3[1]);

        sum1.r += dot(v1[0], k0[0]) + dot(v1[1], k0[1]);
        sum1.g += dot(v1[0], k1[0]) + dot(v1[1], k1[1]);
        sum1.b += dot(v1[0], k2[0]) + dot(v1[1], k2[1]);
        sum1.a += dot(v1[0], k3[0]) + dot(v1[1], k3[1]);

        sum2.r += dot(v2[0], k0[0]) + dot(v2[1], k0[1]);
        sum2.g += dot(v2[0], k1[0]) + dot(v2[1], k1[1]);
        sum2.b += dot(v2[0], k2[0]) + dot(v2[1], k2[1]);
        sum2.a += dot(v2[0], k3[0]) + dot(v2[1], k3[1]);

        sum3.r += dot(v3[0], k0[0]) + dot(v3[1], k0[1]);
        sum3.g += dot(v3[0], k1[0]) + dot(v3[1], k1[1]);
        sum3.b += dot(v3[0], k2[0]) + dot(v3[1], k2[1]);
        sum3.a += dot(v3[0], k3[0]) + dot(v3[1], k3[1]);

        w_offset += 4;
        v_offset += psc(cstep);
    }
#endif

    sum0 = activation_afpvec4(sum0, activation_type, activation_param_0, activation_param_1);
    sum1 = activation_afpvec4(sum1, activation_type, activation_param_0, activation_param_1);
    sum2 = activation_afpvec4(sum2, activation_type, activation_param_0, activation_param_1);
    sum3 = activation_afpvec4(sum3, activation_type, activation_param_0, activation_param_1);

#if NCNN_image_shader
    image3d_st4(top_blob, ivec3(sx4.r, sy4.r, gy), sum0);
    image3d_st4(top_blob, ivec3(sx4.g, sy4.g, gy), sum1);
    image3d_st4(top_blob, ivec3(sx4.b, sy4.b, gy), sum2);
    image3d_st4(top_blob, ivec3(sx4.a, sy4.a, gy), sum3);
#else
    int gi = gy * psc(outcstep) + gx;

    buffer_st4(top_blob_data, gi + 0, sum0);
    if (gx + 1 < psc(outcstep)) buffer_st4(top_blob_data, gi + 1, sum1);
    if (gx + 2 < psc(outcstep)) buffer_st4(top_blob_data, gi + 2, sum2);
    if (gx + 3 < psc(outcstep)) buffer_st4(top_blob_data, gi + 3, sum3);
#endif
}
