// Tencent is pleased to support the open source community by making ncnn available.
//
// Copyright (C) 2025 THL A29 Limited, a Tencent company. All rights reserved.
//
// Licensed under the BSD 3-Clause License (the "License"); you may not use this file except
// in compliance with the License. You may obtain a copy of the License at
//
// https://opensource.org/licenses/BSD-3-Clause
//
// Unless required by applicable law or agreed to in writing, software distributed
// under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR
// CONDITIONS OF ANY KIND, either express or implied. See the License for the
// specific language governing permissions and limitations under the License.

#version 450

#extension GL_GOOGLE_include_directive: require
#include "vulkan_activation.comp"

#extension GL_EXT_control_flow_attributes: require

#extension GL_KHR_memory_scope_semantics: require
#extension GL_EXT_shader_explicit_arithmetic_types: require
#extension GL_EXT_shader_explicit_arithmetic_types_float16: require
#if ncnn_VK_KHR_cooperative_matrix
#extension GL_KHR_cooperative_matrix: require
#elif ncnn_VK_NV_cooperative_matrix
#extension GL_NV_cooperative_matrix: require
#endif

layout (constant_id = 0) const int bias_term = 0;
layout (constant_id = 1) const int activation_type = 0;
layout (constant_id = 2) const float activation_param_0 = 0;
layout (constant_id = 3) const float activation_param_1 = 0;

layout (constant_id = 4) const int M = 1;
layout (constant_id = 5) const int N = 1;
layout (constant_id = 6) const int K = 1;

layout (constant_id = 7) const int UNROLL_M = 1;
layout (constant_id = 8) const int UNROLL_N = 1;

layout (constant_id = 9) const int inch = 1;
layout (constant_id = 10) const int outch = 1;
layout (constant_id = 11) const int elempack = 1;
layout (constant_id = 12) const int out_elempack = 1;

#define shape_constant_id_offset 13
layout (constant_id = shape_constant_id_offset + 0) const int size = 0;
layout (constant_id = shape_constant_id_offset + 1) const int cstep = 0;
layout (constant_id = shape_constant_id_offset + 2) const int outcstep = 0;

layout (binding = 0) readonly buffer bottom_blob { sfpvec4 bottom_blob_data[]; };
layout (binding = 1) writeonly buffer top_blob { sfpvec4 top_blob_data[]; };
layout (binding = 2) readonly buffer weight_blob { sfpvec4 weight_data[]; };
layout (binding = 3) readonly buffer bias_blob { sfpvec4 bias_data[]; };

layout (push_constant) uniform parameter
{
    int size;
    int cstep;
    int outcstep;
} p;

// #define UNROLL_M 2
// #define UNROLL_N 2
// #define UNROLL_K 4

// MxK
shared uvec2 tmp_k[UNROLL_M][M * K / 4];

// KxN
shared uvec2 tmp_v[UNROLL_N][K * N / 4];

// MxN
shared uvec2 tmp_o[UNROLL_M][UNROLL_N][M * N / 4];

void main()
{
    // FIXME hardcode
//     const uint gi = gl_GlobalInvocationID.x / 64;
    const uint gi = gl_WorkGroupID.x;
    const uint li = gl_LocalInvocationID.x;


    // size = (0 ... size)/M  *  (0 ... c)/K

    // v = (0 ... c)/K  *  (0 ... outc)/N

    // gi = (0 ... size)/M  *  (0 ... outc)/N

    // li = 0 1 2 3 .... 31

    const int mm = (outch + (M * UNROLL_M) - 1) / (M * UNROLL_M);
    const int nn = (psc(size) + (N * UNROLL_N) - 1) / (N * UNROLL_N);
    const int kk = (inch + K - 1) / K;

    if (gi >= mm * nn)
        return;

    const uint mi = (gi / nn) * (M * UNROLL_M);
    const uint ni = (gi % nn) * (N * UNROLL_N);

#if ncnn_VK_KHR_cooperative_matrix
    coopmat<afp, gl_ScopeSubgroup, M, N, gl_MatrixUseAccumulator> sum[UNROLL_M][UNROLL_N];
#elif ncnn_VK_NV_cooperative_matrix
#if NCNN_fp16_arithmetic
    fcoopmatNV<16, gl_ScopeSubgroup, M, N> sum[UNROLL_M][UNROLL_N];
#else
    fcoopmatNV<32, gl_ScopeSubgroup, M, N> sum[UNROLL_M][UNROLL_N];
#endif
#endif

    if (bias_term == 1)
    {
        [[unroll]] for (int zm = 0; zm < UNROLL_M; zm++)
        {
#if ncnn_VK_KHR_cooperative_matrix
            coopmat<float16_t, gl_ScopeSubgroup, M, N, gl_MatrixUseAccumulator> bias;
            coopMatLoad(bias, bias_data, (mi + zm * M) / 4, 0, gl_CooperativeMatrixLayoutColumnMajor);
#elif ncnn_VK_NV_cooperative_matrix
            fcoopmatNV<16, gl_ScopeSubgroup, M, N> bias;
            coopMatLoadNV(bias, bias_data, (mi + zm * M) / 4, 0, true);
#endif

#if !NCNN_fp16_arithmetic
#if ncnn_VK_KHR_cooperative_matrix
            coopmat<float, gl_ScopeSubgroup, M, N, gl_MatrixUseAccumulator> bias_fp32 = coopmat<float, gl_ScopeSubgroup, M, N, gl_MatrixUseAccumulator>(bias);
#elif ncnn_VK_NV_cooperative_matrix
            fcoopmatNV<32, gl_ScopeSubgroup, M, N> bias_fp32 = fcoopmatNV<32, gl_ScopeSubgroup, M, N>(bias);
#endif
#endif

            [[unroll]] for (int zn = 0; zn < UNROLL_N; zn++)
            {
#if NCNN_fp16_arithmetic
                sum[zm][zn] = bias;
#else
                sum[zm][zn] = bias_fp32;
#endif
            }
        }
    }
    else
    {
        [[unroll]] for (int zm = 0; zm < UNROLL_M; zm++)
        {
            [[unroll]] for (int zn = 0; zn < UNROLL_N; zn++)
            {
#if ncnn_VK_KHR_cooperative_matrix
                sum[zm][zn] = coopmat<afp, gl_ScopeSubgroup, M, N, gl_MatrixUseAccumulator>(0.f);
#elif ncnn_VK_NV_cooperative_matrix
#if NCNN_fp16_arithmetic
                sum[zm][zn] = fcoopmatNV<16, gl_ScopeSubgroup, M, N>(0.f);
#else
                sum[zm][zn] = fcoopmatNV<32, gl_ScopeSubgroup, M, N>(0.f);
#endif
#endif
            }
        }
    }

    for (int k = 0; k < kk; k++)
    {
        const uint ki = k * K;


        if (li == 0)
        {

        //  +-K-+
        //  |   |
        //  M   |
        //  |   |
        //  +---+

        [[unroll]] for (int zm = 0; zm < UNROLL_M; zm++)
        {
            const int Kd4 = K / 4;
            const int inch_p4d4 = (inch + 3) / 4 * 4;

            // load MxK
            for (int i = 0; i < M; i++)
            {
                for (int j = 0; j < Kd4; j++)
                {
                    const uint gm = mi + zm * M + i;
                    const uint gk = ki + j * 4;

                    afpvec4 v = gm < outch ? buffer_ld4(weight_data, (gm * inch_p4d4 + gk) / 4) : afpvec4(0.f);

                    uvec4 gk4 = gk + uvec4(0, 1, 2, 3);
                    bvec4 gk4ltinch = lessThan(gk4, uvec4(inch));
                    v = mix(afpvec4(0.f), v, gk4ltinch);

                    tmp_k[zm][i * Kd4 + j] = uvec2(packHalf2x16(v.rg), packHalf2x16(v.ba));
                }
            }

        }

        //  +-N-+
        //  |   |
        //  K   |
        //  |   |
        //  +---+

        [[unroll]] for (int zn = 0; zn < UNROLL_N; zn++)
        {

            if (elempack == 1)
            {
                const int Nd4 = N / 4;

                // load KxN
                for (int i = 0; i < K; i++)
                {
                    for (int j = 0; j < Nd4; j++)
                    {
                        const uint gk = ki + i;
                        const uint gn = ni + zn * N + j * 4;

                        afpvec4 v = gk < inch ? buffer_ld4(bottom_blob_data, (gk * psc(cstep) + gn) / 4) : afpvec4(0.f);

                        uvec4 gn4 = gn + uvec4(0, 1, 2, 3);
                        bvec4 gn4ltsize = lessThan(gn4, uvec4(psc(size)));
                        v = mix(afpvec4(0.f), v, gn4ltsize);

                        tmp_v[zn][i * Nd4 + j] = uvec2(packHalf2x16(v.rg), packHalf2x16(v.ba));
                    }
                }

            }
            if (elempack == 4)
            {
                const int Kd4 = K / 4;
                const int Nd4 = N / 4;

                // load KxN
                for (int i = 0; i < Kd4; i++)
                {
                    for (int j = 0; j < Nd4; j++)
                    {
                        const uint gk = ki / 4 + i;
                        const uint gn = ni + zn * N + j * 4;

                        afpvec4 v0 = gk < inch / 4 ? buffer_ld4(bottom_blob_data, gk * psc(cstep) + gn) : afpvec4(0.f);
                        afpvec4 v1 = gk < inch / 4 && gn + 1 < psc(size) ? buffer_ld4(bottom_blob_data, gk * psc(cstep) + gn + 1) : afpvec4(0.f);
                        afpvec4 v2 = gk < inch / 4 && gn + 2 < psc(size) ? buffer_ld4(bottom_blob_data, gk * psc(cstep) + gn + 2) : afpvec4(0.f);
                        afpvec4 v3 = gk < inch / 4 && gn + 3 < psc(size) ? buffer_ld4(bottom_blob_data, gk * psc(cstep) + gn + 3) : afpvec4(0.f);

                        // transpose
                        afpvec4 tv0 = afpvec4(v0.r, v1.r, v2.r, v3.r);
                        afpvec4 tv1 = afpvec4(v0.g, v1.g, v2.g, v3.g);
                        afpvec4 tv2 = afpvec4(v0.b, v1.b, v2.b, v3.b);
                        afpvec4 tv3 = afpvec4(v0.a, v1.a, v2.a, v3.a);

                        tmp_v[zn][i * 4 * Nd4 + j] = uvec2(packHalf2x16(tv0.rg), packHalf2x16(tv0.ba));
                        tmp_v[zn][(i * 4 + 1) * Nd4 + j] = uvec2(packHalf2x16(tv1.rg), packHalf2x16(tv1.ba));
                        tmp_v[zn][(i * 4 + 2) * Nd4 + j] = uvec2(packHalf2x16(tv2.rg), packHalf2x16(tv2.ba));
                        tmp_v[zn][(i * 4 + 3) * Nd4 + j] = uvec2(packHalf2x16(tv3.rg), packHalf2x16(tv3.ba));
                    }
                }

            }

        }

        }

        barrier();

#if ncnn_VK_KHR_cooperative_matrix
        coopmat<float16_t, gl_ScopeSubgroup, M, K, gl_MatrixUseA> A[UNROLL_M];
        coopmat<float16_t, gl_ScopeSubgroup, K, N, gl_MatrixUseB> B[UNROLL_N];
#elif ncnn_VK_NV_cooperative_matrix
        fcoopmatNV<16, gl_ScopeSubgroup, M, K> A[UNROLL_M];
        fcoopmatNV<16, gl_ScopeSubgroup, K, N> B[UNROLL_N];
#endif

        [[unroll]] for (int zm = 0; zm < UNROLL_M; zm++)
        {
#if ncnn_VK_KHR_cooperative_matrix
            coopMatLoad(A[zm], tmp_k[zm], 0, K / 4, gl_CooperativeMatrixLayoutRowMajor);
#elif ncnn_VK_NV_cooperative_matrix
            coopMatLoadNV(A[zm], tmp_k[zm], 0, K / 4, false);
#endif
        }

        [[unroll]] for (int zn = 0; zn < UNROLL_N; zn++)
        {
#if ncnn_VK_KHR_cooperative_matrix
            coopMatLoad(B[zn], tmp_v[zn], 0, N / 4, gl_CooperativeMatrixLayoutRowMajor);
#elif ncnn_VK_NV_cooperative_matrix
            coopMatLoadNV(B[zn], tmp_v[zn], 0, N / 4, false);
#endif
        }

        // sum += k * v
        [[unroll]] for (int zm = 0; zm < UNROLL_M; zm++)
        {
            [[unroll]] for (int zn = 0; zn < UNROLL_N; zn++)
            {
#if ncnn_VK_KHR_cooperative_matrix
                sum[zm][zn] = coopMatMulAdd(A[zm], B[zn], sum[zm][zn]);
#elif ncnn_VK_NV_cooperative_matrix
                sum[zm][zn] = coopMatMulAddNV(A[zm], B[zn], sum[zm][zn]);
#endif
            }
        }

        barrier();
    }

    [[unroll]] for (int zm = 0; zm < UNROLL_M; zm++)
    {
        [[unroll]] for (int zn = 0; zn < UNROLL_N; zn++)
        {
#if ncnn_VK_KHR_cooperative_matrix
#if NCNN_fp16_arithmetic
            coopMatStore(sum[zm][zn], tmp_o[zm][zn], 0, N / 4, gl_CooperativeMatrixLayoutRowMajor);
#else
            coopmat<float16_t, gl_ScopeSubgroup, M, N, gl_MatrixUseAccumulator> sum_fp16 = coopmat<float16_t, gl_ScopeSubgroup, M, N, gl_MatrixUseAccumulator>(sum[zm][zn]);
            coopMatStore(sum_fp16, tmp_o[zm][zn], 0, N / 4, gl_CooperativeMatrixLayoutRowMajor);
#endif
#elif ncnn_VK_NV_cooperative_matrix
#if NCNN_fp16_arithmetic
            coopMatStoreNV(sum[zm][zn], tmp_o[zm][zn], 0, N / 4, false);
#else
            fcoopmatNV<16, gl_ScopeSubgroup, M, N> sum_fp16 = fcoopmatNV<16, gl_ScopeSubgroup, M, N>(sum[zm][zn]);
            coopMatStoreNV(sum_fp16, tmp_o[zm][zn], 0, N / 4, false);
#endif
#endif
        }
    }

    barrier();

    if (li == 0)
    {

    //  +-N-+
    //  |   |
    //  M   |
    //  |   |
    //  +---+

    [[unroll]] for (int zm = 0; zm < UNROLL_M; zm++)
    {
        [[unroll]] for (int zn = 0; zn < UNROLL_N; zn++)
        {

            if (out_elempack == 1)
            {
                const int Nd4 = N / 4;

                // store MxN
                for (int i = 0; i < M; i++)
                {
                for (int j = 0; j < Nd4; j++)
                {
                    const uint gm = mi + zm * M + i;
                    const uint gn = ni + zn * N + j * 4;

                    if (gm < outch && gn < psc(size))
                    {
                        uvec2 sum = tmp_o[zm][zn][i * Nd4 + j];

                        afpvec4 v = afpvec4(unpackHalf2x16(sum.r), unpackHalf2x16(sum.g));

                        v = activation_afpvec4(v, activation_type, activation_param_0, activation_param_1);

                        buffer_st4(top_blob_data, (gm * psc(outcstep) + gn) / 4, v);
                    }
                }
                }

            }
            if (out_elempack == 4)
            {
                const int Md4 = M / 4;
                const int Nd4 = N / 4;

                // store MxN
                for (int i = 0; i < Md4; i++)
                {
                    for (int j = 0; j < Nd4; j++)
                    {
                        const uint gm = (mi + zm * M) / 4 + i;
                        const uint gn = ni + zn * N + j * 4;

                        if (gm < outch / 4 && gn < psc(size))
                        {
                            uvec2 sum0 = tmp_o[zm][zn][i * 4 * Nd4 + j];
                            uvec2 sum1 = tmp_o[zm][zn][(i * 4 + 1) * Nd4 + j];
                            uvec2 sum2 = tmp_o[zm][zn][(i * 4 + 2) * Nd4 + j];
                            uvec2 sum3 = tmp_o[zm][zn][(i * 4 + 3) * Nd4 + j];

                            afpvec4 v0 = afpvec4(unpackHalf2x16(sum0.r), unpackHalf2x16(sum0.g));
                            afpvec4 v1 = afpvec4(unpackHalf2x16(sum1.r), unpackHalf2x16(sum1.g));
                            afpvec4 v2 = afpvec4(unpackHalf2x16(sum2.r), unpackHalf2x16(sum2.g));
                            afpvec4 v3 = afpvec4(unpackHalf2x16(sum3.r), unpackHalf2x16(sum3.g));

                            v0 = activation_afpvec4(v0, activation_type, activation_param_0, activation_param_1);
                            v1 = activation_afpvec4(v1, activation_type, activation_param_0, activation_param_1);
                            v2 = activation_afpvec4(v2, activation_type, activation_param_0, activation_param_1);
                            v3 = activation_afpvec4(v3, activation_type, activation_param_0, activation_param_1);

                            // transpose4x4
                            afpvec4 tv0 = afpvec4(v0.r, v1.r, v2.r, v3.r);
                            afpvec4 tv1 = afpvec4(v0.g, v1.g, v2.g, v3.g);
                            afpvec4 tv2 = afpvec4(v0.b, v1.b, v2.b, v3.b);
                            afpvec4 tv3 = afpvec4(v0.a, v1.a, v2.a, v3.a);

                            buffer_st4(top_blob_data, gm * psc(outcstep) + gn, tv0);
                            if (gn + 1 < psc(size)) buffer_st4(top_blob_data, gm * psc(outcstep) + gn + 1, tv1);
                            if (gn + 2 < psc(size)) buffer_st4(top_blob_data, gm * psc(outcstep) + gn + 2, tv2);
                            if (gn + 3 < psc(size)) buffer_st4(top_blob_data, gm * psc(outcstep) + gn + 3, tv3);
                        }
                    }
                }

            }

        }
    }

    }
}
