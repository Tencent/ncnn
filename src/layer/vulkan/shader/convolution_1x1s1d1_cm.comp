// Tencent is pleased to support the open source community by making ncnn available.
//
// Copyright (C) 2025 THL A29 Limited, a Tencent company. All rights reserved.
//
// Licensed under the BSD 3-Clause License (the "License"); you may not use this file except
// in compliance with the License. You may obtain a copy of the License at
//
// https://opensource.org/licenses/BSD-3-Clause
//
// Unless required by applicable law or agreed to in writing, software distributed
// under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR
// CONDITIONS OF ANY KIND, either express or implied. See the License for the
// specific language governing permissions and limitations under the License.

#version 450

#extension GL_GOOGLE_include_directive: require
#include "vulkan_activation.comp"

#extension GL_EXT_control_flow_attributes: require

#extension GL_KHR_memory_scope_semantics: require
#extension GL_EXT_shader_explicit_arithmetic_types: require
#extension GL_EXT_shader_explicit_arithmetic_types_float16: require
#if ncnn_VK_KHR_cooperative_matrix
#extension GL_KHR_cooperative_matrix: require
#elif ncnn_VK_NV_cooperative_matrix
#extension GL_NV_cooperative_matrix: require
#endif

layout (constant_id = 0) const int bias_term = 0;
layout (constant_id = 1) const int activation_type = 0;
layout (constant_id = 2) const float activation_param_0 = 0;
layout (constant_id = 3) const float activation_param_1 = 0;
layout (constant_id = 4) const uint M = 1;
layout (constant_id = 5) const uint N = 1;
layout (constant_id = 6) const uint K = 1;
layout (constant_id = 7) const uint UNROLL_M = 1;
layout (constant_id = 8) const uint UNROLL_N = 1;
layout (constant_id = 9) const uint inch = 1;
layout (constant_id = 10) const uint outch = 1;
layout (constant_id = 11) const uint elempack = 1;
layout (constant_id = 12) const uint out_elempack = 1;

#define shape_constant_id_offset 13
layout (constant_id = shape_constant_id_offset + 0) const int size = 0;
layout (constant_id = shape_constant_id_offset + 1) const int cstep = 0;
layout (constant_id = shape_constant_id_offset + 2) const int outcstep = 0;

layout (binding = 0) readonly buffer bottom_blob { sfpvec4 bottom_blob_data[]; };
layout (binding = 1) writeonly buffer top_blob { sfpvec4 top_blob_data[]; };
layout (binding = 2) readonly buffer weight_blob { sfpvec4 weight_data[]; };
layout (binding = 3) readonly buffer bias_blob { sfpvec4 bias_data[]; };

layout (push_constant) uniform parameter
{
    int size;
    int cstep;
    int outcstep;
} p;

// MxK
shared uvec2 tmp_k[UNROLL_M][M * K / 4];

// KxN
shared uvec2 tmp_v[UNROLL_N][K * N / 4];

// MxN
shared uvec2 tmp_o[UNROLL_M][UNROLL_N][M * N / 4];

void main()
{
    const uint gi = gl_WorkGroupID.x;
    const uint li = gl_LocalInvocationID.x;

    const uint mm = (outch + (M * UNROLL_M) - 1) / (M * UNROLL_M);
    const uint nn = (psc(size) + (N * UNROLL_N) - 1) / (N * UNROLL_N);
    const uint kk = (inch + K - 1) / K;

    if (gi >= mm * nn)
        return;

    const uint mi = (gi / nn) * (M * UNROLL_M);
    const uint ni = (gi % nn) * (N * UNROLL_N);

#if ncnn_VK_KHR_cooperative_matrix
    coopmat<afp, gl_ScopeSubgroup, M, N, gl_MatrixUseAccumulator> sum[UNROLL_M][UNROLL_N];
#elif ncnn_VK_NV_cooperative_matrix
#if NCNN_fp16_arithmetic
    fcoopmatNV<16, gl_ScopeSubgroup, M, N> sum[UNROLL_M][UNROLL_N];
#else
    fcoopmatNV<32, gl_ScopeSubgroup, M, N> sum[UNROLL_M][UNROLL_N];
#endif
#endif

    if (bias_term == 1)
    {
        [[unroll]] for (uint zm = 0; zm < UNROLL_M; zm++)
        {
#if ncnn_VK_KHR_cooperative_matrix
            coopmat<float16_t, gl_ScopeSubgroup, M, N, gl_MatrixUseAccumulator> bias;
            coopMatLoad(bias, bias_data, (mi + zm * M) / 4, 0, gl_CooperativeMatrixLayoutColumnMajor);
#elif ncnn_VK_NV_cooperative_matrix
            fcoopmatNV<16, gl_ScopeSubgroup, M, N> bias;
            coopMatLoadNV(bias, bias_data, (mi + zm * M) / 4, 0, true);
#endif

#if !NCNN_fp16_arithmetic
#if ncnn_VK_KHR_cooperative_matrix
            coopmat<float, gl_ScopeSubgroup, M, N, gl_MatrixUseAccumulator> bias_fp32 = coopmat<float, gl_ScopeSubgroup, M, N, gl_MatrixUseAccumulator>(bias);
#elif ncnn_VK_NV_cooperative_matrix
            fcoopmatNV<32, gl_ScopeSubgroup, M, N> bias_fp32 = fcoopmatNV<32, gl_ScopeSubgroup, M, N>(bias);
#endif
#endif

            [[unroll]] for (uint zn = 0; zn < UNROLL_N; zn++)
            {
#if NCNN_fp16_arithmetic
                sum[zm][zn] = bias;
#else
                sum[zm][zn] = bias_fp32;
#endif
            }
        }
    }
    else
    {
        [[unroll]] for (uint zm = 0; zm < UNROLL_M; zm++)
        {
            [[unroll]] for (uint zn = 0; zn < UNROLL_N; zn++)
            {
#if ncnn_VK_KHR_cooperative_matrix
                sum[zm][zn] = coopmat<afp, gl_ScopeSubgroup, M, N, gl_MatrixUseAccumulator>(0.f);
#elif ncnn_VK_NV_cooperative_matrix
#if NCNN_fp16_arithmetic
                sum[zm][zn] = fcoopmatNV<16, gl_ScopeSubgroup, M, N>(0.f);
#else
                sum[zm][zn] = fcoopmatNV<32, gl_ScopeSubgroup, M, N>(0.f);
#endif
#endif
            }
        }
    }

    for (uint k = 0; k < kk; k++)
    {
        const uint ki = k * K;

        // load weight
        {
            //  +-K-+
            //  |   |
            //  M   |
            //  |   |
            //  +---+

            const uint Kd4 = K / 4;
            const uint inch_p4d4 = (inch + 3) / 4 * 4;

            const uint UNROLL_M_M_Kd4_d_localsize = (UNROLL_M * M * Kd4 + gl_WorkGroupSize.x - 1) / gl_WorkGroupSize.x;
            [[unroll]] for (uint q = 0; q < UNROLL_M_M_Kd4_d_localsize; q++)
            {
                const uint liq = li + q * gl_WorkGroupSize.x;

                const uint zm = liq / (M * Kd4);
                const uint ij = liq % (M * Kd4);
                const uint i = ij / Kd4;
                const uint j = ij % Kd4;

                if (zm < UNROLL_M && i < M)
                {
                    const uint gm = mi + zm * M + i;
                    const uint gk = ki + j * 4;

                    afpvec4 v = gm < outch ? buffer_ld4(weight_data, (gm * inch_p4d4 + gk) / 4) : afpvec4(0.f);

                    uvec4 gk4 = gk + uvec4(0, 1, 2, 3);
                    bvec4 gk4ltinch = lessThan(gk4, uvec4(inch));
                    v = mix(afpvec4(0.f), v, gk4ltinch);

                    tmp_k[zm][i * Kd4 + j] = uvec2(packHalf2x16(v.rg), packHalf2x16(v.ba));
                }
            }
        }

        // load bottom_blob
        {
            //  +-N-+
            //  |   |
            //  K   |
            //  |   |
            //  +---+

            if (elempack == 1)
            {
                const uint Nd4 = N / 4;

                const uint UNROLL_N_K_Nd4_d_localsize = (UNROLL_N * K * Nd4 + gl_WorkGroupSize.x - 1) / gl_WorkGroupSize.x;
                [[unroll]] for (uint q = 0; q < UNROLL_N_K_Nd4_d_localsize; q++)
                {
                    const uint liq = li + q * gl_WorkGroupSize.x;

                    const uint zn = liq / (K * Nd4);
                    const uint ij = liq % (K * Nd4);
                    const uint i = ij / Nd4;
                    const uint j = ij % Nd4;

                    if (zn < UNROLL_N && i < K)
                    {
                        const uint gk = ki + i;
                        const uint gn = ni + zn * N + j * 4;

                        afpvec4 v = gk < inch ? buffer_ld4(bottom_blob_data, (gk * psc(cstep) + gn) / 4) : afpvec4(0.f);

                        uvec4 gn4 = gn + uvec4(0, 1, 2, 3);
                        bvec4 gn4ltsize = lessThan(gn4, uvec4(psc(size)));
                        v = mix(afpvec4(0.f), v, gn4ltsize);

                        tmp_v[zn][i * Nd4 + j] = uvec2(packHalf2x16(v.rg), packHalf2x16(v.ba));
                    }
                }
            }
            if (elempack == 4)
            {
                const uint Kd4 = K / 4;
                const uint Nd4 = N / 4;

                const uint UNROLL_N_Kd4_Nd4_d_localsize = (UNROLL_N * Kd4 * Nd4 + gl_WorkGroupSize.x - 1) / gl_WorkGroupSize.x;
                [[unroll]] for (uint q = 0; q < UNROLL_N_Kd4_Nd4_d_localsize; q++)
                {
                    const uint liq = li + q * gl_WorkGroupSize.x;

                    const uint zn = liq / (Kd4 * Nd4);
                    const uint ij = liq % (Kd4 * Nd4);
                    const uint i = ij / Nd4;
                    const uint j = ij % Nd4;

                    if (zn < UNROLL_N && i < Kd4)
                    {
                        const uint gk = ki / 4 + i;
                        const uint gn = ni + zn * N + j * 4;

                        afpvec4 v0 = gk < inch / 4 ? buffer_ld4(bottom_blob_data, gk * psc(cstep) + gn) : afpvec4(0.f);
                        afpvec4 v1 = gk < inch / 4 && gn + 1 < psc(size) ? buffer_ld4(bottom_blob_data, gk * psc(cstep) + gn + 1) : afpvec4(0.f);
                        afpvec4 v2 = gk < inch / 4 && gn + 2 < psc(size) ? buffer_ld4(bottom_blob_data, gk * psc(cstep) + gn + 2) : afpvec4(0.f);
                        afpvec4 v3 = gk < inch / 4 && gn + 3 < psc(size) ? buffer_ld4(bottom_blob_data, gk * psc(cstep) + gn + 3) : afpvec4(0.f);

                        // transpose
                        afpvec4 tv0 = afpvec4(v0.r, v1.r, v2.r, v3.r);
                        afpvec4 tv1 = afpvec4(v0.g, v1.g, v2.g, v3.g);
                        afpvec4 tv2 = afpvec4(v0.b, v1.b, v2.b, v3.b);
                        afpvec4 tv3 = afpvec4(v0.a, v1.a, v2.a, v3.a);

                        tmp_v[zn][i * 4 * Nd4 + j] = uvec2(packHalf2x16(tv0.rg), packHalf2x16(tv0.ba));
                        tmp_v[zn][(i * 4 + 1) * Nd4 + j] = uvec2(packHalf2x16(tv1.rg), packHalf2x16(tv1.ba));
                        tmp_v[zn][(i * 4 + 2) * Nd4 + j] = uvec2(packHalf2x16(tv2.rg), packHalf2x16(tv2.ba));
                        tmp_v[zn][(i * 4 + 3) * Nd4 + j] = uvec2(packHalf2x16(tv3.rg), packHalf2x16(tv3.ba));
                    }
                }
            }
        }

        barrier();

#if ncnn_VK_KHR_cooperative_matrix
        coopmat<float16_t, gl_ScopeSubgroup, M, K, gl_MatrixUseA> A[UNROLL_M];
        coopmat<float16_t, gl_ScopeSubgroup, K, N, gl_MatrixUseB> B[UNROLL_N];
#elif ncnn_VK_NV_cooperative_matrix
        fcoopmatNV<16, gl_ScopeSubgroup, M, K> A[UNROLL_M];
        fcoopmatNV<16, gl_ScopeSubgroup, K, N> B[UNROLL_N];
#endif

        [[unroll]] for (uint zm = 0; zm < UNROLL_M; zm++)
        {
#if ncnn_VK_KHR_cooperative_matrix
            coopMatLoad(A[zm], tmp_k[zm], 0, K / 4, gl_CooperativeMatrixLayoutRowMajor);
#elif ncnn_VK_NV_cooperative_matrix
            coopMatLoadNV(A[zm], tmp_k[zm], 0, K / 4, false);
#endif
        }

        [[unroll]] for (uint zn = 0; zn < UNROLL_N; zn++)
        {
#if ncnn_VK_KHR_cooperative_matrix
            coopMatLoad(B[zn], tmp_v[zn], 0, N / 4, gl_CooperativeMatrixLayoutRowMajor);
#elif ncnn_VK_NV_cooperative_matrix
            coopMatLoadNV(B[zn], tmp_v[zn], 0, N / 4, false);
#endif
        }

        // sum += k * v
        [[unroll]] for (uint zm = 0; zm < UNROLL_M; zm++)
        {
            [[unroll]] for (uint zn = 0; zn < UNROLL_N; zn++)
            {
#if ncnn_VK_KHR_cooperative_matrix
                sum[zm][zn] = coopMatMulAdd(A[zm], B[zn], sum[zm][zn]);
#elif ncnn_VK_NV_cooperative_matrix
                sum[zm][zn] = coopMatMulAddNV(A[zm], B[zn], sum[zm][zn]);
#endif
            }
        }

        barrier();
    }

    [[unroll]] for (uint zm = 0; zm < UNROLL_M; zm++)
    {
        [[unroll]] for (uint zn = 0; zn < UNROLL_N; zn++)
        {
#if ncnn_VK_KHR_cooperative_matrix
#if NCNN_fp16_arithmetic
            coopMatStore(sum[zm][zn], tmp_o[zm][zn], 0, N / 4, gl_CooperativeMatrixLayoutRowMajor);
#else
            coopmat<float16_t, gl_ScopeSubgroup, M, N, gl_MatrixUseAccumulator> sum_fp16 = coopmat<float16_t, gl_ScopeSubgroup, M, N, gl_MatrixUseAccumulator>(sum[zm][zn]);
            coopMatStore(sum_fp16, tmp_o[zm][zn], 0, N / 4, gl_CooperativeMatrixLayoutRowMajor);
#endif
#elif ncnn_VK_NV_cooperative_matrix
#if NCNN_fp16_arithmetic
            coopMatStoreNV(sum[zm][zn], tmp_o[zm][zn], 0, N / 4, false);
#else
            fcoopmatNV<16, gl_ScopeSubgroup, M, N> sum_fp16 = fcoopmatNV<16, gl_ScopeSubgroup, M, N>(sum[zm][zn]);
            coopMatStoreNV(sum_fp16, tmp_o[zm][zn], 0, N / 4, false);
#endif
#endif
        }
    }

    barrier();

    // store top_blob
    {
        //  +-N-+
        //  |   |
        //  M   |
        //  |   |
        //  +---+

        if (out_elempack == 1)
        {
            const uint Nd4 = N / 4;

            const uint UNROLL_MN_M_Nd4_d_localsize = (UNROLL_M * UNROLL_N * M * Nd4 + gl_WorkGroupSize.x - 1) / gl_WorkGroupSize.x;
            [[unroll]] for (uint q = 0; q < UNROLL_MN_M_Nd4_d_localsize; q++)
            {
                const uint liq = li + q * gl_WorkGroupSize.x;

                const uint zm = liq / (UNROLL_N * M * Nd4);
                const uint znij = liq % (UNROLL_N * M * Nd4);
                const uint zn = znij / (M * Nd4);
                const uint ij = znij % (M * Nd4);
                const uint i = ij / Nd4;
                const uint j = ij % Nd4;

                const uint gm = mi + zm * M + i;
                const uint gn = ni + zn * N + j * 4;

                if (zm < UNROLL_M && zn < UNROLL_N && i < M && gm < outch && gn < psc(size))
                {
                    uvec2 sum = tmp_o[zm][zn][i * Nd4 + j];

                    afpvec4 v = afpvec4(unpackHalf2x16(sum.r), unpackHalf2x16(sum.g));

                    v = activation_afpvec4(v, activation_type, activation_param_0, activation_param_1);

                    buffer_st4(top_blob_data, (gm * psc(outcstep) + gn) / 4, v);
                }
            }
        }
        if (out_elempack == 4)
        {
            const uint Md4 = M / 4;
            const uint Nd4 = N / 4;

            const uint UNROLL_MN_Md4_Nd4_d_localsize = (UNROLL_M * UNROLL_N * Md4 * Nd4 + gl_WorkGroupSize.x - 1) / gl_WorkGroupSize.x;
            [[unroll]] for (uint q = 0; q < UNROLL_MN_Md4_Nd4_d_localsize; q++)
            {
                const uint liq = li + q * gl_WorkGroupSize.x;

                const uint zm = liq / (UNROLL_N * Md4 * Nd4);
                const uint znij = liq % (UNROLL_N * Md4 * Nd4);
                const uint zn = znij / (Md4 * Nd4);
                const uint ij = znij % (Md4 * Nd4);
                const uint i = ij / Nd4;
                const uint j = ij % Nd4;

                const uint gm = (mi + zm * M) / 4 + i;
                const uint gn = ni + zn * N + j * 4;

                if (zm < UNROLL_M && zn < UNROLL_N && i < Md4 && gm < outch / 4 && gn < psc(size))
                {
                    uvec2 sum0 = tmp_o[zm][zn][i * 4 * Nd4 + j];
                    uvec2 sum1 = tmp_o[zm][zn][(i * 4 + 1) * Nd4 + j];
                    uvec2 sum2 = tmp_o[zm][zn][(i * 4 + 2) * Nd4 + j];
                    uvec2 sum3 = tmp_o[zm][zn][(i * 4 + 3) * Nd4 + j];

                    afpvec4 v0 = afpvec4(unpackHalf2x16(sum0.r), unpackHalf2x16(sum0.g));
                    afpvec4 v1 = afpvec4(unpackHalf2x16(sum1.r), unpackHalf2x16(sum1.g));
                    afpvec4 v2 = afpvec4(unpackHalf2x16(sum2.r), unpackHalf2x16(sum2.g));
                    afpvec4 v3 = afpvec4(unpackHalf2x16(sum3.r), unpackHalf2x16(sum3.g));

                    v0 = activation_afpvec4(v0, activation_type, activation_param_0, activation_param_1);
                    v1 = activation_afpvec4(v1, activation_type, activation_param_0, activation_param_1);
                    v2 = activation_afpvec4(v2, activation_type, activation_param_0, activation_param_1);
                    v3 = activation_afpvec4(v3, activation_type, activation_param_0, activation_param_1);

                    // transpose4x4
                    afpvec4 tv0 = afpvec4(v0.r, v1.r, v2.r, v3.r);
                    afpvec4 tv1 = afpvec4(v0.g, v1.g, v2.g, v3.g);
                    afpvec4 tv2 = afpvec4(v0.b, v1.b, v2.b, v3.b);
                    afpvec4 tv3 = afpvec4(v0.a, v1.a, v2.a, v3.a);

                    buffer_st4(top_blob_data, gm * psc(outcstep) + gn, tv0);
                    if (gn + 1 < psc(size)) buffer_st4(top_blob_data, gm * psc(outcstep) + gn + 1, tv1);
                    if (gn + 2 < psc(size)) buffer_st4(top_blob_data, gm * psc(outcstep) + gn + 2, tv2);
                    if (gn + 3 < psc(size)) buffer_st4(top_blob_data, gm * psc(outcstep) + gn + 3, tv3);
                }
            }
        }
    }
}
