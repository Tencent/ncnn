// Tencent is pleased to support the open source community by making ncnn available.
//
// Copyright (C) 2022 THL A29 Limited, a Tencent company. All rights reserved.
//
// Licensed under the BSD 3-Clause License (the "License"); you may not use this file except
// in compliance with the License. You may obtain a copy of the License at
//
// https://opensource.org/licenses/BSD-3-Clause
//
// Unless required by applicable law or agreed to in writing, software distributed
// under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR
// CONDITIONS OF ANY KIND, either express or implied. See the License for the
// specific language governing permissions and limitations under the License.

#version 450

#if NCNN_fp16_storage
#extension GL_EXT_shader_16bit_storage: require
struct sfpvec8 { f16vec4 abcd; f16vec4 efgh; };
#endif
#if NCNN_fp16_arithmetic
#extension GL_EXT_shader_explicit_arithmetic_types_float16: require
#endif

#define shape_constant_id_offset 0
layout (constant_id = shape_constant_id_offset + 0) const int w = 0;
layout (constant_id = shape_constant_id_offset + 1) const int h = 0;
layout (constant_id = shape_constant_id_offset + 2) const int c = 0;
layout (constant_id = shape_constant_id_offset + 3) const int cstep = 0;

layout (constant_id = shape_constant_id_offset + 4) const int outcstep = 0;

layout (constant_id = shape_constant_id_offset + 5) const int block_x = 0;
layout (constant_id = shape_constant_id_offset + 6) const int block_y = 0;

#if NCNN_image_shader
layout (binding = 0) uniform unfp sampler3D bottom_blob;
layout (binding = 1, imfmtc4) writeonly uniform unfp image3D bottom_tm_blob;
#else
layout (binding = 0) readonly buffer bottom_blob { sfpvec8 bottom_blob_data[]; };
layout (binding = 1) writeonly buffer bottom_tm_blob { sfpvec8 bottom_tm_blob_data[]; };
#endif

layout (push_constant) uniform parameter
{
    int w;
    int h;
    int c;
    int cstep;

    int outcstep;

    int block_x;
    int block_y;
} p;

void main()
{
    int gx = int(gl_GlobalInvocationID.x);
    int gy = int(gl_GlobalInvocationID.y);
    int gz = int(gl_GlobalInvocationID.z);

    if (gx >= p.block_x || gy >= p.block_y || gz >= psc(c))
        return;

    // load 6x6
#if NCNN_image_shader
    int sx = gx * 4;
    int sy = gy * 4;

    afpvec8 v00 = image3d_ld8(bottom_blob, ivec3(sx + 0, sy + 0, gz));
    afpvec8 v01 = image3d_ld8(bottom_blob, ivec3(sx + 1, sy + 0, gz));
    afpvec8 v02 = image3d_ld8(bottom_blob, ivec3(sx + 2, sy + 0, gz));
    afpvec8 v03 = image3d_ld8(bottom_blob, ivec3(sx + 3, sy + 0, gz));
    afpvec8 v04 = image3d_ld8(bottom_blob, ivec3(sx + 4, sy + 0, gz));
    afpvec8 v05 = image3d_ld8(bottom_blob, ivec3(sx + 5, sy + 0, gz));

    afpvec8 v10 = image3d_ld8(bottom_blob, ivec3(sx + 0, sy + 1, gz));
    afpvec8 v11 = image3d_ld8(bottom_blob, ivec3(sx + 1, sy + 1, gz));
    afpvec8 v12 = image3d_ld8(bottom_blob, ivec3(sx + 2, sy + 1, gz));
    afpvec8 v13 = image3d_ld8(bottom_blob, ivec3(sx + 3, sy + 1, gz));
    afpvec8 v14 = image3d_ld8(bottom_blob, ivec3(sx + 4, sy + 1, gz));
    afpvec8 v15 = image3d_ld8(bottom_blob, ivec3(sx + 5, sy + 1, gz));

    afpvec8 v20 = image3d_ld8(bottom_blob, ivec3(sx + 0, sy + 2, gz));
    afpvec8 v21 = image3d_ld8(bottom_blob, ivec3(sx + 1, sy + 2, gz));
    afpvec8 v22 = image3d_ld8(bottom_blob, ivec3(sx + 2, sy + 2, gz));
    afpvec8 v23 = image3d_ld8(bottom_blob, ivec3(sx + 3, sy + 2, gz));
    afpvec8 v24 = image3d_ld8(bottom_blob, ivec3(sx + 4, sy + 2, gz));
    afpvec8 v25 = image3d_ld8(bottom_blob, ivec3(sx + 5, sy + 2, gz));

    afpvec8 v30 = image3d_ld8(bottom_blob, ivec3(sx + 0, sy + 3, gz));
    afpvec8 v31 = image3d_ld8(bottom_blob, ivec3(sx + 1, sy + 3, gz));
    afpvec8 v32 = image3d_ld8(bottom_blob, ivec3(sx + 2, sy + 3, gz));
    afpvec8 v33 = image3d_ld8(bottom_blob, ivec3(sx + 3, sy + 3, gz));
    afpvec8 v34 = image3d_ld8(bottom_blob, ivec3(sx + 4, sy + 3, gz));
    afpvec8 v35 = image3d_ld8(bottom_blob, ivec3(sx + 5, sy + 3, gz));

    afpvec8 v40 = image3d_ld8(bottom_blob, ivec3(sx + 0, sy + 4, gz));
    afpvec8 v41 = image3d_ld8(bottom_blob, ivec3(sx + 1, sy + 4, gz));
    afpvec8 v42 = image3d_ld8(bottom_blob, ivec3(sx + 2, sy + 4, gz));
    afpvec8 v43 = image3d_ld8(bottom_blob, ivec3(sx + 3, sy + 4, gz));
    afpvec8 v44 = image3d_ld8(bottom_blob, ivec3(sx + 4, sy + 4, gz));
    afpvec8 v45 = image3d_ld8(bottom_blob, ivec3(sx + 5, sy + 4, gz));

    afpvec8 v50 = image3d_ld8(bottom_blob, ivec3(sx + 0, sy + 5, gz));
    afpvec8 v51 = image3d_ld8(bottom_blob, ivec3(sx + 1, sy + 5, gz));
    afpvec8 v52 = image3d_ld8(bottom_blob, ivec3(sx + 2, sy + 5, gz));
    afpvec8 v53 = image3d_ld8(bottom_blob, ivec3(sx + 3, sy + 5, gz));
    afpvec8 v54 = image3d_ld8(bottom_blob, ivec3(sx + 4, sy + 5, gz));
    afpvec8 v55 = image3d_ld8(bottom_blob, ivec3(sx + 5, sy + 5, gz));
#else
    int v_offset_0 = gz * psc(cstep) + gy * 4 * psc(w) + gx * 4;
    ivec4 v_offset = v_offset_0 + ivec4(0, 1, 2, 3) * psc(w);
    ivec2 v_offset45 = v_offset_0 + ivec2(4, 5) * psc(w);

    afpvec8 v00 = buffer_ld8(bottom_blob_data, v_offset.r + 0);
    afpvec8 v01 = buffer_ld8(bottom_blob_data, v_offset.r + 1);
    afpvec8 v02 = buffer_ld8(bottom_blob_data, v_offset.r + 2);
    afpvec8 v03 = buffer_ld8(bottom_blob_data, v_offset.r + 3);
    afpvec8 v04 = buffer_ld8(bottom_blob_data, v_offset.r + 4);
    afpvec8 v05 = buffer_ld8(bottom_blob_data, v_offset.r + 5);

    afpvec8 v10 = buffer_ld8(bottom_blob_data, v_offset.g + 0);
    afpvec8 v11 = buffer_ld8(bottom_blob_data, v_offset.g + 1);
    afpvec8 v12 = buffer_ld8(bottom_blob_data, v_offset.g + 2);
    afpvec8 v13 = buffer_ld8(bottom_blob_data, v_offset.g + 3);
    afpvec8 v14 = buffer_ld8(bottom_blob_data, v_offset.g + 4);
    afpvec8 v15 = buffer_ld8(bottom_blob_data, v_offset.g + 5);

    afpvec8 v20 = buffer_ld8(bottom_blob_data, v_offset.b + 0);
    afpvec8 v21 = buffer_ld8(bottom_blob_data, v_offset.b + 1);
    afpvec8 v22 = buffer_ld8(bottom_blob_data, v_offset.b + 2);
    afpvec8 v23 = buffer_ld8(bottom_blob_data, v_offset.b + 3);
    afpvec8 v24 = buffer_ld8(bottom_blob_data, v_offset.b + 4);
    afpvec8 v25 = buffer_ld8(bottom_blob_data, v_offset.b + 5);

    afpvec8 v30 = buffer_ld8(bottom_blob_data, v_offset.a + 0);
    afpvec8 v31 = buffer_ld8(bottom_blob_data, v_offset.a + 1);
    afpvec8 v32 = buffer_ld8(bottom_blob_data, v_offset.a + 2);
    afpvec8 v33 = buffer_ld8(bottom_blob_data, v_offset.a + 3);
    afpvec8 v34 = buffer_ld8(bottom_blob_data, v_offset.a + 4);
    afpvec8 v35 = buffer_ld8(bottom_blob_data, v_offset.a + 5);

    afpvec8 v40 = buffer_ld8(bottom_blob_data, v_offset45.x + 0);
    afpvec8 v41 = buffer_ld8(bottom_blob_data, v_offset45.x + 1);
    afpvec8 v42 = buffer_ld8(bottom_blob_data, v_offset45.x + 2);
    afpvec8 v43 = buffer_ld8(bottom_blob_data, v_offset45.x + 3);
    afpvec8 v44 = buffer_ld8(bottom_blob_data, v_offset45.x + 4);
    afpvec8 v45 = buffer_ld8(bottom_blob_data, v_offset45.x + 5);

    afpvec8 v50 = buffer_ld8(bottom_blob_data, v_offset45.y + 0);
    afpvec8 v51 = buffer_ld8(bottom_blob_data, v_offset45.y + 1);
    afpvec8 v52 = buffer_ld8(bottom_blob_data, v_offset45.y + 2);
    afpvec8 v53 = buffer_ld8(bottom_blob_data, v_offset45.y + 3);
    afpvec8 v54 = buffer_ld8(bottom_blob_data, v_offset45.y + 4);
    afpvec8 v55 = buffer_ld8(bottom_blob_data, v_offset45.y + 5);
#endif

    // const float itm[6][6] = {
    //     {1.0f, 0.0f, -1.25f, 0.0f, 0.25f, 0.0f},
    //     {0.0f,-1.0f, -1.0f, 0.25f, 0.25f, 0.0f},
    //     {0.0f, 1.0f, -1.0f,-0.25f, 0.25f, 0.0f},
    //     {0.0f,-0.5f, -0.25f, 0.5f, 0.25f, 0.0f},
    //     {0.0f, 0.5f, -0.25f,-0.5f, 0.25f, 0.0f},
    //     {0.0f, 1.0f,  0.0f,-1.25f, 0.0f, 0.25f}
    // };

    // 0 =  1 * r00 - 1.25 * r02 + 0.25 * r04
    // 1 = -1 * (r01 + r02) + 0.25 * (r04 + r03)
    // 2 =  1 * (r01 - r02) + 0.25 * (r04 - r03)
    // 3 = -0.5 * (r01 - r03) + 0.25 * (r04 - r02)
    // 4 =  0.5 * (r01 - r03) + 0.25 * (r04 - r02)
    // 5 =  1 * r01 - 1.25 * r03 + 0.25 * r05

    // implicit transpose
    afpvec8 m00 = v00 - v02 * afp(1.25) + v04 * afp(0.25);
    afpvec8 m01 = v10 - v12 * afp(1.25) + v14 * afp(0.25);
    afpvec8 m02 = v20 - v22 * afp(1.25) + v24 * afp(0.25);
    afpvec8 m03 = v30 - v32 * afp(1.25) + v34 * afp(0.25);
    afpvec8 m04 = v40 - v42 * afp(1.25) + v44 * afp(0.25);
    afpvec8 m05 = v50 - v52 * afp(1.25) + v54 * afp(0.25);

    afpvec8 m10 = (v04 + v03) * afp(0.25) - (v01 + v02);
    afpvec8 m11 = (v14 + v13) * afp(0.25) - (v11 + v12);
    afpvec8 m12 = (v24 + v23) * afp(0.25) - (v21 + v22);
    afpvec8 m13 = (v34 + v33) * afp(0.25) - (v31 + v32);
    afpvec8 m14 = (v44 + v43) * afp(0.25) - (v41 + v42);
    afpvec8 m15 = (v54 + v53) * afp(0.25) - (v51 + v52);

    afpvec8 m20 = (v04 - v03) * afp(0.25) + (v01 - v02);
    afpvec8 m21 = (v14 - v13) * afp(0.25) + (v11 - v12);
    afpvec8 m22 = (v24 - v23) * afp(0.25) + (v21 - v22);
    afpvec8 m23 = (v34 - v33) * afp(0.25) + (v31 - v32);
    afpvec8 m24 = (v44 - v43) * afp(0.25) + (v41 - v42);
    afpvec8 m25 = (v54 - v53) * afp(0.25) + (v51 - v52);

    afpvec8 m30 = (v04 - v02) * afp(0.25) - (v01 - v03) * afp(0.5);
    afpvec8 m31 = (v14 - v12) * afp(0.25) - (v11 - v13) * afp(0.5);
    afpvec8 m32 = (v24 - v22) * afp(0.25) - (v21 - v23) * afp(0.5);
    afpvec8 m33 = (v34 - v32) * afp(0.25) - (v31 - v33) * afp(0.5);
    afpvec8 m34 = (v44 - v42) * afp(0.25) - (v41 - v43) * afp(0.5);
    afpvec8 m35 = (v54 - v52) * afp(0.25) - (v51 - v53) * afp(0.5);

    afpvec8 m40 = (v04 - v02) * afp(0.25) + (v01 - v03) * afp(0.5);
    afpvec8 m41 = (v14 - v12) * afp(0.25) + (v11 - v13) * afp(0.5);
    afpvec8 m42 = (v24 - v22) * afp(0.25) + (v21 - v23) * afp(0.5);
    afpvec8 m43 = (v34 - v32) * afp(0.25) + (v31 - v33) * afp(0.5);
    afpvec8 m44 = (v44 - v42) * afp(0.25) + (v41 - v43) * afp(0.5);
    afpvec8 m45 = (v54 - v52) * afp(0.25) + (v51 - v53) * afp(0.5);

    afpvec8 m50 = v01 - v03 * afp(1.25) + v05 * afp(0.25);
    afpvec8 m51 = v11 - v13 * afp(1.25) + v15 * afp(0.25);
    afpvec8 m52 = v21 - v23 * afp(1.25) + v25 * afp(0.25);
    afpvec8 m53 = v31 - v33 * afp(1.25) + v35 * afp(0.25);
    afpvec8 m54 = v41 - v43 * afp(1.25) + v45 * afp(0.25);
    afpvec8 m55 = v51 - v53 * afp(1.25) + v55 * afp(0.25);

    v00 = m00 - m02 * afp(1.25) + m04 * afp(0.25);
    v10 = m10 - m12 * afp(1.25) + m14 * afp(0.25);
    v20 = m20 - m22 * afp(1.25) + m24 * afp(0.25);
    v30 = m30 - m32 * afp(1.25) + m34 * afp(0.25);
    v40 = m40 - m42 * afp(1.25) + m44 * afp(0.25);
    v50 = m50 - m52 * afp(1.25) + m54 * afp(0.25);

    v01 = (m04 + m03) * afp(0.25) - (m01 + m02);
    v11 = (m14 + m13) * afp(0.25) - (m11 + m12);
    v21 = (m24 + m23) * afp(0.25) - (m21 + m22);
    v31 = (m34 + m33) * afp(0.25) - (m31 + m32);
    v41 = (m44 + m43) * afp(0.25) - (m41 + m42);
    v51 = (m54 + m53) * afp(0.25) - (m51 + m52);

    v02 = (m04 - m03) * afp(0.25) + (m01 - m02);
    v12 = (m14 - m13) * afp(0.25) + (m11 - m12);
    v22 = (m24 - m23) * afp(0.25) + (m21 - m22);
    v32 = (m34 - m33) * afp(0.25) + (m31 - m32);
    v42 = (m44 - m43) * afp(0.25) + (m41 - m42);
    v52 = (m54 - m53) * afp(0.25) + (m51 - m52);

    v03 = (m04 - m02) * afp(0.25) - (m01 - m03) * afp(0.5);
    v13 = (m14 - m12) * afp(0.25) - (m11 - m13) * afp(0.5);
    v23 = (m24 - m22) * afp(0.25) - (m21 - m23) * afp(0.5);
    v33 = (m34 - m32) * afp(0.25) - (m31 - m33) * afp(0.5);
    v43 = (m44 - m42) * afp(0.25) - (m41 - m43) * afp(0.5);
    v53 = (m54 - m52) * afp(0.25) - (m51 - m53) * afp(0.5);

    v04 = (m04 - m02) * afp(0.25) + (m01 - m03) * afp(0.5);
    v14 = (m14 - m12) * afp(0.25) + (m11 - m13) * afp(0.5);
    v24 = (m24 - m22) * afp(0.25) + (m21 - m23) * afp(0.5);
    v34 = (m34 - m32) * afp(0.25) + (m31 - m33) * afp(0.5);
    v44 = (m44 - m42) * afp(0.25) + (m41 - m43) * afp(0.5);
    v54 = (m54 - m52) * afp(0.25) + (m51 - m53) * afp(0.5);

    v05 = m01 - m03 * afp(1.25) + m05 * afp(0.25);
    v15 = m11 - m13 * afp(1.25) + m15 * afp(0.25);
    v25 = m21 - m23 * afp(1.25) + m25 * afp(0.25);
    v35 = m31 - m33 * afp(1.25) + m35 * afp(0.25);
    v45 = m41 - m43 * afp(1.25) + m45 * afp(0.25);
    v55 = m51 - m53 * afp(1.25) + m55 * afp(0.25);

    // store 36
#if NCNN_image_shader
    int y = gy * p.block_x + gx;

    image3d_st8(bottom_tm_blob, ivec3(0, y, gz), v00);
    image3d_st8(bottom_tm_blob, ivec3(1, y, gz), v01);
    image3d_st8(bottom_tm_blob, ivec3(2, y, gz), v02);
    image3d_st8(bottom_tm_blob, ivec3(3, y, gz), v03);
    image3d_st8(bottom_tm_blob, ivec3(4, y, gz), v04);
    image3d_st8(bottom_tm_blob, ivec3(5, y, gz), v05);
    image3d_st8(bottom_tm_blob, ivec3(6, y, gz), v10);
    image3d_st8(bottom_tm_blob, ivec3(7, y, gz), v11);
    image3d_st8(bottom_tm_blob, ivec3(8, y, gz), v12);
    image3d_st8(bottom_tm_blob, ivec3(9, y, gz), v13);
    image3d_st8(bottom_tm_blob, ivec3(10, y, gz), v14);
    image3d_st8(bottom_tm_blob, ivec3(11, y, gz), v15);
    image3d_st8(bottom_tm_blob, ivec3(12, y, gz), v20);
    image3d_st8(bottom_tm_blob, ivec3(13, y, gz), v21);
    image3d_st8(bottom_tm_blob, ivec3(14, y, gz), v22);
    image3d_st8(bottom_tm_blob, ivec3(15, y, gz), v23);
    image3d_st8(bottom_tm_blob, ivec3(16, y, gz), v24);
    image3d_st8(bottom_tm_blob, ivec3(17, y, gz), v25);
    image3d_st8(bottom_tm_blob, ivec3(18, y, gz), v30);
    image3d_st8(bottom_tm_blob, ivec3(19, y, gz), v31);
    image3d_st8(bottom_tm_blob, ivec3(20, y, gz), v32);
    image3d_st8(bottom_tm_blob, ivec3(21, y, gz), v33);
    image3d_st8(bottom_tm_blob, ivec3(22, y, gz), v34);
    image3d_st8(bottom_tm_blob, ivec3(23, y, gz), v35);
    image3d_st8(bottom_tm_blob, ivec3(24, y, gz), v40);
    image3d_st8(bottom_tm_blob, ivec3(25, y, gz), v41);
    image3d_st8(bottom_tm_blob, ivec3(26, y, gz), v42);
    image3d_st8(bottom_tm_blob, ivec3(27, y, gz), v43);
    image3d_st8(bottom_tm_blob, ivec3(28, y, gz), v44);
    image3d_st8(bottom_tm_blob, ivec3(29, y, gz), v45);
    image3d_st8(bottom_tm_blob, ivec3(30, y, gz), v50);
    image3d_st8(bottom_tm_blob, ivec3(31, y, gz), v51);
    image3d_st8(bottom_tm_blob, ivec3(32, y, gz), v52);
    image3d_st8(bottom_tm_blob, ivec3(33, y, gz), v53);
    image3d_st8(bottom_tm_blob, ivec3(34, y, gz), v54);
    image3d_st8(bottom_tm_blob, ivec3(35, y, gz), v55);
#else
    int v_tm_offset = gz * psc(outcstep) + (gy * p.block_x + gx) * 36;

    buffer_st8(bottom_tm_blob_data, v_tm_offset + 0, v00);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 1, v01);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 2, v02);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 3, v03);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 4, v04);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 5, v05);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 6, v10);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 7, v11);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 8, v12);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 9, v13);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 10, v14);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 11, v15);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 12, v20);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 13, v21);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 14, v22);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 15, v23);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 16, v24);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 17, v25);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 18, v30);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 19, v31);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 20, v32);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 21, v33);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 22, v34);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 23, v35);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 24, v40);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 25, v41);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 26, v42);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 27, v43);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 28, v44);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 29, v45);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 30, v50);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 31, v51);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 32, v52);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 33, v53);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 34, v54);
    buffer_st8(bottom_tm_blob_data, v_tm_offset + 35, v55);
#endif
}
