// Tencent is pleased to support the open source community by making ncnn available.
//
// Copyright (C) 2020 THL A29 Limited, a Tencent company. All rights reserved.
//
// Licensed under the BSD 3-Clause License (the "License"); you may not use this file except
// in compliance with the License. You may obtain a copy of the License at
//
// https://opensource.org/licenses/BSD-3-Clause
//
// Unless required by applicable law or agreed to in writing, software distributed
// under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR
// CONDITIONS OF ANY KIND, either express or implied. See the License for the
// specific language governing permissions and limitations under the License.

#version 450

#if NCNN_fp16_storage
#extension GL_EXT_shader_16bit_storage: require
struct sfpvec8 { f16vec4 abcd; f16vec4 efgh; };
#endif
#if NCNN_fp16_arithmetic
#extension GL_EXT_shader_explicit_arithmetic_types_float16: require
#endif

#define shape_constant_id_offset 0
layout (constant_id = shape_constant_id_offset + 0) const int c = 0;
layout (constant_id = shape_constant_id_offset + 1) const int cstep = 0;

layout (constant_id = shape_constant_id_offset + 2) const int outh = 0;
layout (constant_id = shape_constant_id_offset + 3) const int outc = 0;
layout (constant_id = shape_constant_id_offset + 4) const int outcstep = 0;

#if NCNN_image_shader
layout (binding = 0) uniform unfp sampler3D bottom_tm_blob;
layout (binding = 1, imfmtc4) writeonly uniform unfp image3D top_tm_blob;
layout (binding = 2) uniform unfp sampler3D weight_tm_blob;
#else
layout (binding = 0) readonly buffer bottom_tm_blob { sfpvec8 bottom_tm_blob_data[]; };
layout (binding = 1) writeonly buffer top_tm_blob { sfpvec8 top_tm_blob_data[]; };
layout (binding = 2) readonly buffer weight_tm_blob { sfpvec8 weight_tm_data[]; };
#endif

layout (push_constant) uniform parameter
{
    int c;
    int cstep;

    int outh;
    int outc;
    int outcstep;
} p;

void main()
{
    int gx = int(gl_GlobalInvocationID.x);
    int gy = int(gl_GlobalInvocationID.y) * 4;
    int gz = int(gl_GlobalInvocationID.z);

    if (gx >= 16 || gy >= psc(outh) || gz >= psc(outc))
        return;

    afpvec8 sum0 = afpvec8(afpvec4(0.f), afpvec4(0.f));
    afpvec8 sum1 = afpvec8(afpvec4(0.f), afpvec4(0.f));
    afpvec8 sum2 = afpvec8(afpvec4(0.f), afpvec4(0.f));
    afpvec8 sum3 = afpvec8(afpvec4(0.f), afpvec4(0.f));

#if NCNN_image_shader
    int wx = gx * 8;

    for (int z = 0; z < psc(c); z++)
    {
        afpvec8 v0 = image3d_ld8(bottom_tm_blob, ivec3(gx, gy + 0, z));
        afpvec8 v1 = image3d_ld8(bottom_tm_blob, ivec3(gx, gy + 1, z));
        afpvec8 v2 = image3d_ld8(bottom_tm_blob, ivec3(gx, gy + 2, z));
        afpvec8 v3 = image3d_ld8(bottom_tm_blob, ivec3(gx, gy + 3, z));

        afpvec8 k0 = image3d_ld8(weight_tm_blob, ivec3(wx + 0, z, gz));
        afpvec8 k1 = image3d_ld8(weight_tm_blob, ivec3(wx + 1, z, gz));
        afpvec8 k2 = image3d_ld8(weight_tm_blob, ivec3(wx + 2, z, gz));
        afpvec8 k3 = image3d_ld8(weight_tm_blob, ivec3(wx + 3, z, gz));
        afpvec8 k4 = image3d_ld8(weight_tm_blob, ivec3(wx + 4, z, gz));
        afpvec8 k5 = image3d_ld8(weight_tm_blob, ivec3(wx + 5, z, gz));
        afpvec8 k6 = image3d_ld8(weight_tm_blob, ivec3(wx + 6, z, gz));
        afpvec8 k7 = image3d_ld8(weight_tm_blob, ivec3(wx + 7, z, gz));

        // sum += v * k
        sum0[0].r += dot(v0[0], k0[0]) + dot(v0[1], k0[1]);
        sum0[0].g += dot(v0[0], k1[0]) + dot(v0[1], k1[1]);
        sum0[0].b += dot(v0[0], k2[0]) + dot(v0[1], k2[1]);
        sum0[0].a += dot(v0[0], k3[0]) + dot(v0[1], k3[1]);
        sum0[1].r += dot(v0[0], k4[0]) + dot(v0[1], k4[1]);
        sum0[1].g += dot(v0[0], k5[0]) + dot(v0[1], k5[1]);
        sum0[1].b += dot(v0[0], k6[0]) + dot(v0[1], k6[1]);
        sum0[1].a += dot(v0[0], k7[0]) + dot(v0[1], k7[1]);

        sum1[0].r += dot(v1[0], k0[0]) + dot(v1[1], k0[1]);
        sum1[0].g += dot(v1[0], k1[0]) + dot(v1[1], k1[1]);
        sum1[0].b += dot(v1[0], k2[0]) + dot(v1[1], k2[1]);
        sum1[0].a += dot(v1[0], k3[0]) + dot(v1[1], k3[1]);
        sum1[1].r += dot(v1[0], k4[0]) + dot(v1[1], k4[1]);
        sum1[1].g += dot(v1[0], k5[0]) + dot(v1[1], k5[1]);
        sum1[1].b += dot(v1[0], k6[0]) + dot(v1[1], k6[1]);
        sum1[1].a += dot(v1[0], k7[0]) + dot(v1[1], k7[1]);

        sum2[0].r += dot(v2[0], k0[0]) + dot(v2[1], k0[1]);
        sum2[0].g += dot(v2[0], k1[0]) + dot(v2[1], k1[1]);
        sum2[0].b += dot(v2[0], k2[0]) + dot(v2[1], k2[1]);
        sum2[0].a += dot(v2[0], k3[0]) + dot(v2[1], k3[1]);
        sum2[1].r += dot(v2[0], k4[0]) + dot(v2[1], k4[1]);
        sum2[1].g += dot(v2[0], k5[0]) + dot(v2[1], k5[1]);
        sum2[1].b += dot(v2[0], k6[0]) + dot(v2[1], k6[1]);
        sum2[1].a += dot(v2[0], k7[0]) + dot(v2[1], k7[1]);

        sum3[0].r += dot(v3[0], k0[0]) + dot(v3[1], k0[1]);
        sum3[0].g += dot(v3[0], k1[0]) + dot(v3[1], k1[1]);
        sum3[0].b += dot(v3[0], k2[0]) + dot(v3[1], k2[1]);
        sum3[0].a += dot(v3[0], k3[0]) + dot(v3[1], k3[1]);
        sum3[1].r += dot(v3[0], k4[0]) + dot(v3[1], k4[1]);
        sum3[1].g += dot(v3[0], k5[0]) + dot(v3[1], k5[1]);
        sum3[1].b += dot(v3[0], k6[0]) + dot(v3[1], k6[1]);
        sum3[1].a += dot(v3[0], k7[0]) + dot(v3[1], k7[1]);
    }
#else
    int v_offset = gy * 16 + gx;
    int w_offset = (gz * psc(c) * 16 + gx) * 8;

    for (int z = 0; z < psc(c); z++)
    {
        afpvec8 v0 = buffer_ld8(bottom_tm_blob_data, v_offset + 0);
        afpvec8 v1 = buffer_ld8(bottom_tm_blob_data, v_offset + 16);
        afpvec8 v2 = buffer_ld8(bottom_tm_blob_data, v_offset + 32);
        afpvec8 v3 = buffer_ld8(bottom_tm_blob_data, v_offset + 48);

        afpvec8 k0 = buffer_ld8(weight_tm_data, w_offset + 0);
        afpvec8 k1 = buffer_ld8(weight_tm_data, w_offset + 1);
        afpvec8 k2 = buffer_ld8(weight_tm_data, w_offset + 2);
        afpvec8 k3 = buffer_ld8(weight_tm_data, w_offset + 3);
        afpvec8 k4 = buffer_ld8(weight_tm_data, w_offset + 4);
        afpvec8 k5 = buffer_ld8(weight_tm_data, w_offset + 5);
        afpvec8 k6 = buffer_ld8(weight_tm_data, w_offset + 6);
        afpvec8 k7 = buffer_ld8(weight_tm_data, w_offset + 7);

        // sum += v * k
        sum0[0].r += dot(v0[0], k0[0]) + dot(v0[1], k0[1]);
        sum0[0].g += dot(v0[0], k1[0]) + dot(v0[1], k1[1]);
        sum0[0].b += dot(v0[0], k2[0]) + dot(v0[1], k2[1]);
        sum0[0].a += dot(v0[0], k3[0]) + dot(v0[1], k3[1]);
        sum0[1].r += dot(v0[0], k4[0]) + dot(v0[1], k4[1]);
        sum0[1].g += dot(v0[0], k5[0]) + dot(v0[1], k5[1]);
        sum0[1].b += dot(v0[0], k6[0]) + dot(v0[1], k6[1]);
        sum0[1].a += dot(v0[0], k7[0]) + dot(v0[1], k7[1]);

        sum1[0].r += dot(v1[0], k0[0]) + dot(v1[1], k0[1]);
        sum1[0].g += dot(v1[0], k1[0]) + dot(v1[1], k1[1]);
        sum1[0].b += dot(v1[0], k2[0]) + dot(v1[1], k2[1]);
        sum1[0].a += dot(v1[0], k3[0]) + dot(v1[1], k3[1]);
        sum1[1].r += dot(v1[0], k4[0]) + dot(v1[1], k4[1]);
        sum1[1].g += dot(v1[0], k5[0]) + dot(v1[1], k5[1]);
        sum1[1].b += dot(v1[0], k6[0]) + dot(v1[1], k6[1]);
        sum1[1].a += dot(v1[0], k7[0]) + dot(v1[1], k7[1]);

        sum2[0].r += dot(v2[0], k0[0]) + dot(v2[1], k0[1]);
        sum2[0].g += dot(v2[0], k1[0]) + dot(v2[1], k1[1]);
        sum2[0].b += dot(v2[0], k2[0]) + dot(v2[1], k2[1]);
        sum2[0].a += dot(v2[0], k3[0]) + dot(v2[1], k3[1]);
        sum2[1].r += dot(v2[0], k4[0]) + dot(v2[1], k4[1]);
        sum2[1].g += dot(v2[0], k5[0]) + dot(v2[1], k5[1]);
        sum2[1].b += dot(v2[0], k6[0]) + dot(v2[1], k6[1]);
        sum2[1].a += dot(v2[0], k7[0]) + dot(v2[1], k7[1]);

        sum3[0].r += dot(v3[0], k0[0]) + dot(v3[1], k0[1]);
        sum3[0].g += dot(v3[0], k1[0]) + dot(v3[1], k1[1]);
        sum3[0].b += dot(v3[0], k2[0]) + dot(v3[1], k2[1]);
        sum3[0].a += dot(v3[0], k3[0]) + dot(v3[1], k3[1]);
        sum3[1].r += dot(v3[0], k4[0]) + dot(v3[1], k4[1]);
        sum3[1].g += dot(v3[0], k5[0]) + dot(v3[1], k5[1]);
        sum3[1].b += dot(v3[0], k6[0]) + dot(v3[1], k6[1]);
        sum3[1].a += dot(v3[0], k7[0]) + dot(v3[1], k7[1]);

        v_offset += psc(cstep);
        w_offset += 16 * 8;
    }
#endif

#if NCNN_image_shader
    image3d_st8(top_tm_blob, ivec3(gx, gy + 0, gz), sum0);
    image3d_st8(top_tm_blob, ivec3(gx, gy + 1, gz), sum1);
    image3d_st8(top_tm_blob, ivec3(gx, gy + 2, gz), sum2);
    image3d_st8(top_tm_blob, ivec3(gx, gy + 3, gz), sum3);
#else
    int gi = gz * psc(outcstep) + gy * 16 + gx;

    buffer_st8(top_tm_blob_data, gi + 0, sum0);
    if (gy + 1 < psc(outh)) buffer_st8(top_tm_blob_data, gi + 16, sum1);
    if (gy + 2 < psc(outh)) buffer_st8(top_tm_blob_data, gi + 32, sum2);
    if (gy + 3 < psc(outh)) buffer_st8(top_tm_blob_data, gi + 48, sum3);
#endif
}
