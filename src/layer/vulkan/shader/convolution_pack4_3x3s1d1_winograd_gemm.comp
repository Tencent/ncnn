// Tencent is pleased to support the open source community by making ncnn available.
//
// Copyright (C) 2022 THL A29 Limited, a Tencent company. All rights reserved.
//
// Licensed under the BSD 3-Clause License (the "License"); you may not use this file except
// in compliance with the License. You may obtain a copy of the License at
//
// https://opensource.org/licenses/BSD-3-Clause
//
// Unless required by applicable law or agreed to in writing, software distributed
// under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR
// CONDITIONS OF ANY KIND, either express or implied. See the License for the
// specific language governing permissions and limitations under the License.

#version 450

#if NCNN_fp16_storage
#extension GL_EXT_shader_16bit_storage: require
#endif
#if NCNN_fp16_arithmetic
#extension GL_EXT_shader_explicit_arithmetic_types_float16: require
#endif

#define LOCAL_MEMORY_UNROLL_INCH 8

layout (constant_id = 0) const int batch = 1;

#define shape_constant_id_offset 1
layout (constant_id = shape_constant_id_offset + 0) const int c = 0;
layout (constant_id = shape_constant_id_offset + 1) const int cstep = 0;

layout (constant_id = shape_constant_id_offset + 2) const int outw = 0;
layout (constant_id = shape_constant_id_offset + 3) const int outc = 0;
layout (constant_id = shape_constant_id_offset + 4) const int outcstep = 0;

#if NCNN_image_shader
layout (binding = 0) uniform unfp sampler3D bottom_tm_blob;
layout (binding = 1, imfmtc4) writeonly uniform unfp image3D top_tm_blob;
layout (binding = 2) uniform unfp sampler3D weight_tm_blob;
#else
layout (binding = 0) readonly buffer bottom_tm_blob { sfpvec4 bottom_tm_blob_data[]; };
layout (binding = 1) writeonly buffer top_tm_blob { sfpvec4 top_tm_blob_data[]; };
layout (binding = 2) readonly buffer weight_tm_blob { sfpvec4 weight_tm_data[]; };
#endif

layout (push_constant) uniform parameter
{
    int c;
    int cstep;

    int outw;
    int outc;
    int outcstep;
} p;

#if NCNN_shader_local_memory
shared lfpvec4 tmp_v[8][LOCAL_MEMORY_UNROLL_INCH][4];
shared lfpvec4 tmp_k[8][LOCAL_MEMORY_UNROLL_INCH][4];
#endif

void main()
{
    int gx = int(gl_GlobalInvocationID.x) * 4;
    int gy = int(gl_GlobalInvocationID.y);
    int gz = int(gl_GlobalInvocationID.z);

#if !NCNN_shader_local_memory
    if (gx >= psc(outw) || gy >= psc(outc) || gz >= batch)
        return;
#endif

    afpvec4 sum0 = afpvec4(0.f);
    afpvec4 sum1 = afpvec4(0.f);
    afpvec4 sum2 = afpvec4(0.f);
    afpvec4 sum3 = afpvec4(0.f);

#if NCNN_image_shader
    for (int z = 0; z < psc(c); z++)
    {
        afpvec4 v0 = image3d_ld4(bottom_tm_blob, ivec3(gx + 0, z, gz));
        afpvec4 v1 = image3d_ld4(bottom_tm_blob, ivec3(gx + 1, z, gz));
        afpvec4 v2 = image3d_ld4(bottom_tm_blob, ivec3(gx + 2, z, gz));
        afpvec4 v3 = image3d_ld4(bottom_tm_blob, ivec3(gx + 3, z, gz));

        afpmat4 k = afpmat4(
            image3d_ld4(weight_tm_blob, ivec3(z * 4 + 0, gy, gz)),
            image3d_ld4(weight_tm_blob, ivec3(z * 4 + 1, gy, gz)),
            image3d_ld4(weight_tm_blob, ivec3(z * 4 + 2, gy, gz)),
            image3d_ld4(weight_tm_blob, ivec3(z * 4 + 3, gy, gz))
        );

        sum0 += v0 * k;
        sum1 += v1 * k;
        sum2 += v2 * k;
        sum3 += v3 * k;
    }
#else
    int v_offset = gz * psc(cstep) + gx;
    int w_offset = (gz * psc(c) * psc(outc) + gy * psc(c)) * 4;

#if NCNN_shader_local_memory
    const int lx = int(gl_LocalInvocationID.x);
    const int ly = int(gl_LocalInvocationID.y);

    int z = 0;
    for (; z + (LOCAL_MEMORY_UNROLL_INCH - 1) < psc(c); z += LOCAL_MEMORY_UNROLL_INCH)
    {
        if (ly < 4)
        {
            for (int z4 = 0; z4 < LOCAL_MEMORY_UNROLL_INCH; z4++)
            {
                tmp_v[lx][z4][ly] = sfp2lfpvec4(bottom_tm_blob_data[v_offset + z4 * psc(outw) + ly]);
            }
        }

        if (lx < 4)
        {
            for (int z4 = 0; z4 < LOCAL_MEMORY_UNROLL_INCH; z4++)
            {
                tmp_k[ly][z4][lx] = sfp2lfpvec4(weight_tm_data[w_offset + z4 * 4 + lx]);
            }
        }

        barrier();

        for (int z4 = 0; z4 < LOCAL_MEMORY_UNROLL_INCH; z4++)
        {
            afpvec4 v0 = lfp2afpvec4(tmp_v[lx][z4][0]);
            afpvec4 v1 = lfp2afpvec4(tmp_v[lx][z4][1]);
            afpvec4 v2 = lfp2afpvec4(tmp_v[lx][z4][2]);
            afpvec4 v3 = lfp2afpvec4(tmp_v[lx][z4][3]);

            afpvec4 k0 = lfp2afpvec4(tmp_k[ly][z4][0]);
            afpvec4 k1 = lfp2afpvec4(tmp_k[ly][z4][1]);
            afpvec4 k2 = lfp2afpvec4(tmp_k[ly][z4][2]);
            afpvec4 k3 = lfp2afpvec4(tmp_k[ly][z4][3]);

            afpmat4 k = afpmat4(k0, k1, k2, k3);

            sum0 += v0 * k;
            sum1 += v1 * k;
            sum2 += v2 * k;
            sum3 += v3 * k;
        }

        v_offset += LOCAL_MEMORY_UNROLL_INCH * psc(outw);
        w_offset += LOCAL_MEMORY_UNROLL_INCH * 4;

        barrier();
    }

    if (z < psc(c))
    {
        const int remain = psc(c) - z;

        if (ly < 4)
        {
            for (int z4 = 0; z4 < remain; z4++)
            {
                tmp_v[lx][z4][ly] = sfp2lfpvec4(bottom_tm_blob_data[v_offset + z4 * psc(outw) + ly]);
            }
        }

        if (lx < 4)
        {
            for (int z4 = 0; z4 < remain; z4++)
            {
                tmp_k[ly][z4][lx] = sfp2lfpvec4(weight_tm_data[w_offset + z4 * 4 + lx]);
            }
        }

        barrier();

        for (int z4 = 0; z4 < remain; z4++)
        {
            afpvec4 v0 = lfp2afpvec4(tmp_v[lx][z4][0]);
            afpvec4 v1 = lfp2afpvec4(tmp_v[lx][z4][1]);
            afpvec4 v2 = lfp2afpvec4(tmp_v[lx][z4][2]);
            afpvec4 v3 = lfp2afpvec4(tmp_v[lx][z4][3]);

            afpvec4 k0 = lfp2afpvec4(tmp_k[ly][z4][0]);
            afpvec4 k1 = lfp2afpvec4(tmp_k[ly][z4][1]);
            afpvec4 k2 = lfp2afpvec4(tmp_k[ly][z4][2]);
            afpvec4 k3 = lfp2afpvec4(tmp_k[ly][z4][3]);

            afpmat4 k = afpmat4(k0, k1, k2, k3);

            sum0 += v0 * k;
            sum1 += v1 * k;
            sum2 += v2 * k;
            sum3 += v3 * k;
        }
    }
#else
    for (int z = 0; z < psc(c); z++)
    {
        afpvec4 v0 = buffer_ld4(bottom_tm_blob_data, v_offset + 0);
        afpvec4 v1 = buffer_ld4(bottom_tm_blob_data, v_offset + 1);
        afpvec4 v2 = buffer_ld4(bottom_tm_blob_data, v_offset + 2);
        afpvec4 v3 = buffer_ld4(bottom_tm_blob_data, v_offset + 3);

        afpmat4 k = afpmat4(
            buffer_ld4(weight_tm_data, w_offset + 0),
            buffer_ld4(weight_tm_data, w_offset + 1),
            buffer_ld4(weight_tm_data, w_offset + 2),
            buffer_ld4(weight_tm_data, w_offset + 3)
        );

        sum0 += v0 * k;
        sum1 += v1 * k;
        sum2 += v2 * k;
        sum3 += v3 * k;

        v_offset += psc(outw);
        w_offset += 4;
    }
#endif
#endif

#if NCNN_shader_local_memory
    if (gx >= psc(outw) || gy >= psc(outc) || gz >= batch)
        return;
#endif

#if NCNN_image_shader
    image3d_st4(top_tm_blob, ivec3(gx + 0, gy, gz), sum0);
    image3d_st4(top_tm_blob, ivec3(gx + 1, gy, gz), sum1);
    image3d_st4(top_tm_blob, ivec3(gx + 2, gy, gz), sum2);
    image3d_st4(top_tm_blob, ivec3(gx + 3, gy, gz), sum3);
#else
    int gi = gz * psc(outcstep) + gy * psc(outw) + gx;

    buffer_st4(top_tm_blob_data, gi + 0, sum0);
    if (gx + 1 < psc(outw)) buffer_st4(top_tm_blob_data, gi + 1, sum1);
    if (gx + 2 < psc(outw)) buffer_st4(top_tm_blob_data, gi + 2, sum2);
    if (gx + 3 < psc(outw)) buffer_st4(top_tm_blob_data, gi + 3, sum3);
#endif
}
