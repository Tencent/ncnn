// Tencent is pleased to support the open source community by making ncnn available.
//
// Copyright (C) 2020 THL A29 Limited, a Tencent company. All rights reserved.
//
// Licensed under the BSD 3-Clause License (the "License"); you may not use this file except
// in compliance with the License. You may obtain a copy of the License at
//
// https://opensource.org/licenses/BSD-3-Clause
//
// Unless required by applicable law or agreed to in writing, software distributed
// under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR
// CONDITIONS OF ANY KIND, either express or implied. See the License for the
// specific language governing permissions and limitations under the License.

#version 450

#if NCNN_fp16_storage
#extension GL_EXT_shader_16bit_storage: require
struct sfpvec8 { f16vec4 abcd; f16vec4 efgh; };
#endif
#if NCNN_fp16_arithmetic
#extension GL_EXT_shader_explicit_arithmetic_types_float16: require
#endif

#extension GL_GOOGLE_include_directive: enable
#include "vulkan_activation.comp"

layout (constant_id = 0) const int kernel_w = 1;
layout (constant_id = 1) const int kernel_h = 1;
layout (constant_id = 2) const int dilation_w = 1;
layout (constant_id = 3) const int dilation_h = 1;
layout (constant_id = 4) const int stride_w = 1;
layout (constant_id = 5) const int stride_h = 1;
layout (constant_id = 6) const int bias_term = 0;
layout (constant_id = 7) const int activation_type = 0;
layout (constant_id = 8) const float activation_param_0 = 0;
layout (constant_id = 9) const float activation_param_1 = 0;

#define shape_constant_id_offset 10
layout (constant_id = shape_constant_id_offset + 0) const int dims = 0;
layout (constant_id = shape_constant_id_offset + 1) const int w = 0;
layout (constant_id = shape_constant_id_offset + 2) const int h = 0;
layout (constant_id = shape_constant_id_offset + 3) const int c = 0;
layout (constant_id = shape_constant_id_offset + 4) const int cstep = 0;

layout (constant_id = shape_constant_id_offset + 5) const int outdims = 0;
layout (constant_id = shape_constant_id_offset + 6) const int outw = 0;
layout (constant_id = shape_constant_id_offset + 7) const int outh = 0;
layout (constant_id = shape_constant_id_offset + 8) const int outc = 0;
layout (constant_id = shape_constant_id_offset + 9) const int outcstep = 0;

#if NCNN_image_shader
layout (binding = 0) uniform unfp sampler3D bottom_blob;
layout (binding = 1, imfmtc4) writeonly uniform unfp image3D top_blob;
layout (binding = 2) uniform unfp sampler3D weight_blob;
layout (binding = 3) uniform unfp sampler3D bias_blob;
#else
layout (binding = 0) readonly buffer bottom_blob { sfpvec4 bottom_blob_data[]; };
layout (binding = 1) writeonly buffer top_blob { sfpvec8 top_blob_data[]; };
layout (binding = 2) readonly buffer weight_blob { sfpvec4 weight_data[]; };
layout (binding = 3) readonly buffer bias_blob { sfpvec8 bias_data[]; };
#endif

layout (push_constant) uniform parameter
{
    int dims;
    int w;
    int h;
    int c;
    int cstep;

    int outdims;
    int outw;
    int outh;
    int outc;
    int outcstep;
} p;

void main()
{
    int gx = int(gl_GlobalInvocationID.x) * 2;
    int gy = int(gl_GlobalInvocationID.y) * 2;
    int gz = int(gl_GlobalInvocationID.z) * 2;

    if (gx >= psc(outw) || gy >= psc(outh) || gz >= psc(outc))
        return;

    const ivec2 gx2 = gx + ivec2(0, 1);
    const ivec2 gy2 = gy + ivec2(0, 1);
    const ivec2 gz2 = gz + ivec2(0, 1);

    afpvec8 sum0;
    afpvec8 sum1;
    afpvec8 sum2;
    afpvec8 sum3;
    afpvec8 sum4;
    afpvec8 sum5;
    afpvec8 sum6;
    afpvec8 sum7;

    if (bias_term == 1)
    {
#if NCNN_image_shader
        sum0 = image3d_ld8(bias_blob, ivec3(gz2.x, 0, 0));
        sum4 = image3d_ld8(bias_blob, ivec3(gz2.y, 0, 0));
#else
        sum0 = buffer_ld8(bias_data, gz2.x);
        sum4 = buffer_ld8(bias_data, gz2.y);
#endif
        sum1 = sum0;
        sum2 = sum0;
        sum3 = sum0;
        sum5 = sum4;
        sum6 = sum4;
        sum7 = sum4;
    }
    else
    {
        sum0 = afpvec8(afpvec4(0.f), afpvec4(0.f));
        sum1 = afpvec8(afpvec4(0.f), afpvec4(0.f));
        sum2 = afpvec8(afpvec4(0.f), afpvec4(0.f));
        sum3 = afpvec8(afpvec4(0.f), afpvec4(0.f));
        sum4 = afpvec8(afpvec4(0.f), afpvec4(0.f));
        sum5 = afpvec8(afpvec4(0.f), afpvec4(0.f));
        sum6 = afpvec8(afpvec4(0.f), afpvec4(0.f));
        sum7 = afpvec8(afpvec4(0.f), afpvec4(0.f));
    }

#if NCNN_image_shader
    for (int z = 0; z < psc(c); z++)
    {
        ivec2 sy = gy2 * stride_h;
        int wx = 0;

        for (int y = 0; y < kernel_h; y++)
        {
            ivec2 sx = gx2 * stride_w;

            for (int x = 0; x < kernel_w; x++)
            {
                afpvec4 v0 = image3d_ld4(bottom_blob, ivec3(sx.x, sy.x, z));
                afpvec4 v1 = image3d_ld4(bottom_blob, ivec3(sx.y, sy.x, z));
                afpvec4 v2 = image3d_ld4(bottom_blob, ivec3(sx.x, sy.y, z));
                afpvec4 v3 = image3d_ld4(bottom_blob, ivec3(sx.y, sy.y, z));

                afpvec4 k0 = image3d_ld4(weight_blob, ivec3(wx + 0, z, gz2.x));
                afpvec4 k1 = image3d_ld4(weight_blob, ivec3(wx + 1, z, gz2.x));
                afpvec4 k2 = image3d_ld4(weight_blob, ivec3(wx + 2, z, gz2.x));
                afpvec4 k3 = image3d_ld4(weight_blob, ivec3(wx + 3, z, gz2.x));
                afpvec4 k4 = image3d_ld4(weight_blob, ivec3(wx + 4, z, gz2.x));
                afpvec4 k5 = image3d_ld4(weight_blob, ivec3(wx + 5, z, gz2.x));
                afpvec4 k6 = image3d_ld4(weight_blob, ivec3(wx + 6, z, gz2.x));
                afpvec4 k7 = image3d_ld4(weight_blob, ivec3(wx + 7, z, gz2.x));

                afpvec4 k8 = image3d_ld4(weight_blob, ivec3(wx + 0, z, gz2.y));
                afpvec4 k9 = image3d_ld4(weight_blob, ivec3(wx + 1, z, gz2.y));
                afpvec4 ka = image3d_ld4(weight_blob, ivec3(wx + 2, z, gz2.y));
                afpvec4 kb = image3d_ld4(weight_blob, ivec3(wx + 3, z, gz2.y));
                afpvec4 kc = image3d_ld4(weight_blob, ivec3(wx + 4, z, gz2.y));
                afpvec4 kd = image3d_ld4(weight_blob, ivec3(wx + 5, z, gz2.y));
                afpvec4 ke = image3d_ld4(weight_blob, ivec3(wx + 6, z, gz2.y));
                afpvec4 kf = image3d_ld4(weight_blob, ivec3(wx + 7, z, gz2.y));

                // sum += v * k;
                sum0[0].r += dot(v0, k0);
                sum0[0].g += dot(v0, k1);
                sum0[0].b += dot(v0, k2);
                sum0[0].a += dot(v0, k3);
                sum0[1].r += dot(v0, k4);
                sum0[1].g += dot(v0, k5);
                sum0[1].b += dot(v0, k6);
                sum0[1].a += dot(v0, k7);
                sum1[0].r += dot(v1, k0);
                sum1[0].g += dot(v1, k1);
                sum1[0].b += dot(v1, k2);
                sum1[0].a += dot(v1, k3);
                sum1[1].r += dot(v1, k4);
                sum1[1].g += dot(v1, k5);
                sum1[1].b += dot(v1, k6);
                sum1[1].a += dot(v1, k7);
                sum2[0].r += dot(v2, k0);
                sum2[0].g += dot(v2, k1);
                sum2[0].b += dot(v2, k2);
                sum2[0].a += dot(v2, k3);
                sum2[1].r += dot(v2, k4);
                sum2[1].g += dot(v2, k5);
                sum2[1].b += dot(v2, k6);
                sum2[1].a += dot(v2, k7);
                sum3[0].r += dot(v3, k0);
                sum3[0].g += dot(v3, k1);
                sum3[0].b += dot(v3, k2);
                sum3[0].a += dot(v3, k3);
                sum3[1].r += dot(v3, k4);
                sum3[1].g += dot(v3, k5);
                sum3[1].b += dot(v3, k6);
                sum3[1].a += dot(v3, k7);

                sum4[0].r += dot(v0, k8);
                sum4[0].g += dot(v0, k9);
                sum4[0].b += dot(v0, ka);
                sum4[0].a += dot(v0, kb);
                sum4[1].r += dot(v0, kc);
                sum4[1].g += dot(v0, kd);
                sum4[1].b += dot(v0, ke);
                sum4[1].a += dot(v0, kf);
                sum5[0].r += dot(v1, k8);
                sum5[0].g += dot(v1, k9);
                sum5[0].b += dot(v1, ka);
                sum5[0].a += dot(v1, kb);
                sum5[1].r += dot(v1, kc);
                sum5[1].g += dot(v1, kd);
                sum5[1].b += dot(v1, ke);
                sum5[1].a += dot(v1, kf);
                sum6[0].r += dot(v2, k8);
                sum6[0].g += dot(v2, k9);
                sum6[0].b += dot(v2, ka);
                sum6[0].a += dot(v2, kb);
                sum6[1].r += dot(v2, kc);
                sum6[1].g += dot(v2, kd);
                sum6[1].b += dot(v2, ke);
                sum6[1].a += dot(v2, kf);
                sum7[0].r += dot(v3, k8);
                sum7[0].g += dot(v3, k9);
                sum7[0].b += dot(v3, ka);
                sum7[0].a += dot(v3, kb);
                sum7[1].r += dot(v3, kc);
                sum7[1].g += dot(v3, kd);
                sum7[1].b += dot(v3, ke);
                sum7[1].a += dot(v3, kf);

                sx += dilation_w;
                wx += 8;
            }

            sy += dilation_h;
        }
    }
#else
    ivec2 w_offset = gz2 * psc(c) * kernel_w * kernel_h;

    for (int z = 0; z < psc(c); z++)
    {
        ivec4 v_offset;
        v_offset.rg = z * psc(cstep) + gy2.x * stride_h * psc(w) + gx2 * stride_w;
        v_offset.ba = z * psc(cstep) + gy2.y * stride_h * psc(w) + gx2 * stride_w;

        for (int y = 0; y < kernel_h; y++)
        {
            for (int x = 0; x < kernel_w; x++)
            {
                afpvec4 v0 = buffer_ld4(bottom_blob_data, v_offset.r + x * dilation_w);
                afpvec4 v1 = buffer_ld4(bottom_blob_data, v_offset.g + x * dilation_w);
                afpvec4 v2 = buffer_ld4(bottom_blob_data, v_offset.b + x * dilation_w);
                afpvec4 v3 = buffer_ld4(bottom_blob_data, v_offset.a + x * dilation_w);

                afpvec4 k0 = buffer_ld4(weight_data, (w_offset.x + x) * 8 + 0);
                afpvec4 k1 = buffer_ld4(weight_data, (w_offset.x + x) * 8 + 1);
                afpvec4 k2 = buffer_ld4(weight_data, (w_offset.x + x) * 8 + 2);
                afpvec4 k3 = buffer_ld4(weight_data, (w_offset.x + x) * 8 + 3);
                afpvec4 k4 = buffer_ld4(weight_data, (w_offset.x + x) * 8 + 4);
                afpvec4 k5 = buffer_ld4(weight_data, (w_offset.x + x) * 8 + 5);
                afpvec4 k6 = buffer_ld4(weight_data, (w_offset.x + x) * 8 + 6);
                afpvec4 k7 = buffer_ld4(weight_data, (w_offset.x + x) * 8 + 7);

                afpvec4 k8 = buffer_ld4(weight_data, (w_offset.y + x) * 8 + 0);
                afpvec4 k9 = buffer_ld4(weight_data, (w_offset.y + x) * 8 + 1);
                afpvec4 ka = buffer_ld4(weight_data, (w_offset.y + x) * 8 + 2);
                afpvec4 kb = buffer_ld4(weight_data, (w_offset.y + x) * 8 + 3);
                afpvec4 kc = buffer_ld4(weight_data, (w_offset.y + x) * 8 + 4);
                afpvec4 kd = buffer_ld4(weight_data, (w_offset.y + x) * 8 + 5);
                afpvec4 ke = buffer_ld4(weight_data, (w_offset.y + x) * 8 + 6);
                afpvec4 kf = buffer_ld4(weight_data, (w_offset.y + x) * 8 + 7);

                // sum += v * k;
                sum0[0].r += dot(v0, k0);
                sum0[0].g += dot(v0, k1);
                sum0[0].b += dot(v0, k2);
                sum0[0].a += dot(v0, k3);
                sum0[1].r += dot(v0, k4);
                sum0[1].g += dot(v0, k5);
                sum0[1].b += dot(v0, k6);
                sum0[1].a += dot(v0, k7);
                sum1[0].r += dot(v1, k0);
                sum1[0].g += dot(v1, k1);
                sum1[0].b += dot(v1, k2);
                sum1[0].a += dot(v1, k3);
                sum1[1].r += dot(v1, k4);
                sum1[1].g += dot(v1, k5);
                sum1[1].b += dot(v1, k6);
                sum1[1].a += dot(v1, k7);
                sum2[0].r += dot(v2, k0);
                sum2[0].g += dot(v2, k1);
                sum2[0].b += dot(v2, k2);
                sum2[0].a += dot(v2, k3);
                sum2[1].r += dot(v2, k4);
                sum2[1].g += dot(v2, k5);
                sum2[1].b += dot(v2, k6);
                sum2[1].a += dot(v2, k7);
                sum3[0].r += dot(v3, k0);
                sum3[0].g += dot(v3, k1);
                sum3[0].b += dot(v3, k2);
                sum3[0].a += dot(v3, k3);
                sum3[1].r += dot(v3, k4);
                sum3[1].g += dot(v3, k5);
                sum3[1].b += dot(v3, k6);
                sum3[1].a += dot(v3, k7);

                sum4[0].r += dot(v0, k8);
                sum4[0].g += dot(v0, k9);
                sum4[0].b += dot(v0, ka);
                sum4[0].a += dot(v0, kb);
                sum4[1].r += dot(v0, kc);
                sum4[1].g += dot(v0, kd);
                sum4[1].b += dot(v0, ke);
                sum4[1].a += dot(v0, kf);
                sum5[0].r += dot(v1, k8);
                sum5[0].g += dot(v1, k9);
                sum5[0].b += dot(v1, ka);
                sum5[0].a += dot(v1, kb);
                sum5[1].r += dot(v1, kc);
                sum5[1].g += dot(v1, kd);
                sum5[1].b += dot(v1, ke);
                sum5[1].a += dot(v1, kf);
                sum6[0].r += dot(v2, k8);
                sum6[0].g += dot(v2, k9);
                sum6[0].b += dot(v2, ka);
                sum6[0].a += dot(v2, kb);
                sum6[1].r += dot(v2, kc);
                sum6[1].g += dot(v2, kd);
                sum6[1].b += dot(v2, ke);
                sum6[1].a += dot(v2, kf);
                sum7[0].r += dot(v3, k8);
                sum7[0].g += dot(v3, k9);
                sum7[0].b += dot(v3, ka);
                sum7[0].a += dot(v3, kb);
                sum7[1].r += dot(v3, kc);
                sum7[1].g += dot(v3, kd);
                sum7[1].b += dot(v3, ke);
                sum7[1].a += dot(v3, kf);
            }

            v_offset += dilation_h * psc(w);
            w_offset += kernel_w;
        }
    }
#endif

    sum0 = activation_afpvec8(sum0, activation_type, activation_param_0, activation_param_1);
    sum1 = activation_afpvec8(sum1, activation_type, activation_param_0, activation_param_1);
    sum2 = activation_afpvec8(sum2, activation_type, activation_param_0, activation_param_1);
    sum3 = activation_afpvec8(sum3, activation_type, activation_param_0, activation_param_1);
    sum4 = activation_afpvec8(sum4, activation_type, activation_param_0, activation_param_1);
    sum5 = activation_afpvec8(sum5, activation_type, activation_param_0, activation_param_1);
    sum6 = activation_afpvec8(sum6, activation_type, activation_param_0, activation_param_1);
    sum7 = activation_afpvec8(sum7, activation_type, activation_param_0, activation_param_1);

#if NCNN_image_shader
    image3d_st8(top_blob, ivec3(gx2.x, gy2.x, gz2.x), sum0);
    image3d_st8(top_blob, ivec3(gx2.y, gy2.x, gz2.x), sum1);
    image3d_st8(top_blob, ivec3(gx2.x, gy2.y, gz2.x), sum2);
    image3d_st8(top_blob, ivec3(gx2.y, gy2.y, gz2.x), sum3);
    image3d_st8(top_blob, ivec3(gx2.x, gy2.x, gz2.y), sum4);
    image3d_st8(top_blob, ivec3(gx2.y, gy2.x, gz2.y), sum5);
    image3d_st8(top_blob, ivec3(gx2.x, gy2.y, gz2.y), sum6);
    image3d_st8(top_blob, ivec3(gx2.y, gy2.y, gz2.y), sum7);
#else
    const ivec2 gi = gz2 * psc(outcstep) + gy * psc(outw) + gx;

    buffer_st8(top_blob_data, gi.x, sum0);
    if (gx + 1 < psc(outw)) buffer_st8(top_blob_data, gi.x + 1, sum1);
    if (gy + 1 < psc(outh)) buffer_st8(top_blob_data, gi.x + psc(outw), sum2);
    if (gy + 1 < psc(outh) && gx + 1 < psc(outw)) buffer_st8(top_blob_data, gi.x + psc(outw) + 1, sum3);
    if (gz + 1 < psc(outc))
    {
        buffer_st8(top_blob_data, gi.y, sum4);
        if (gx + 1 < psc(outw)) buffer_st8(top_blob_data, gi.y + 1, sum5);
        if (gy + 1 < psc(outh)) buffer_st8(top_blob_data, gi.y + psc(outw), sum6);
        if (gy + 1 < psc(outh) && gx + 1 < psc(outw)) buffer_st8(top_blob_data, gi.y + psc(outw) + 1, sum7);
    }
#endif
}
